# ğŸŒ¤ï¸ ModÃ¨le ML pour la DÃ©tection d'Anomalies dans la Consommation Ã‰nergÃ©tique BasÃ©e sur les DonnÃ©es MÃ©tÃ©orologiques

## Langage
![Python](https://img.shields.io/badge/python-3.11.5-blue)

## Frameworks et Outils de DÃ©veloppement
![Streamlit](https://img.shields.io/badge/Streamlit-1.38.0-brightgreen)
![MLflow](https://img.shields.io/badge/MLflow-2.1.6-orange)
![Docker](https://img.shields.io/badge/Docker-Enabled-blue)
![Kedro Badge](https://img.shields.io/badge/Kedro-0.19.8-brightgreen)

### Empreinte Carbone
![CodeCarbon](https://img.shields.io/badge/CodeCarbon-2.7.1-green)

## Sommaire

1. [ğŸ“– PrÃ©sentation du Projet](#prÃ©sentation-du-projet)
2. [ğŸ› ï¸ Installation et DÃ©marrage du Projet](#installation-et-dÃ©marrage-du-projet)
3. [ğŸ“‚ Structure du Projet](#structure-du-projet)
4. [ğŸš€ FonctionnalitÃ©s Principales](#fonctionnalitÃ©s-principales)
5. [ğŸ“ˆ IntÃ©gration avec Kedro et Streamlit](#intÃ©gration-avec-kedro-et-streamlit)
6. [ğŸ“Š ModÃ¨les et Algorithmes UtilisÃ©s](#modÃ¨les-et-algorithmes-utilisÃ©s)
7. [ğŸ“ˆ IntÃ©gration avec MLFlow](#intÃ©gration-avec-mlflow)
8. [ğŸŒ± Empreinte Carbone avec CodeCarbon](#empreinte-carbone-avec-codecarbon)


## ğŸ“– PrÃ©sentation du sous-projet<a name="prÃ©sentation-du-projet"></a>

Ce sous-projet fait partie de la solution globale de **DÃ©tection d'Anomalies** dans la consommation d'Ã©nergie. Son objectif est de prÃ©dire et d'identifier des anomalies dans les comportements de consommation Ã©nergÃ©tique, en prenant en compte les donnÃ©es mÃ©tÃ©orologiques.

Nous utilisons des algorithmes intÃ©grÃ©s dans des **pipelines Kedro** pour le traitement des donnÃ©es et l'entraÃ®nement des modÃ¨les. De plus, une interface interactive, dÃ©veloppÃ©e avec **Streamlit**, permet de visualiser en temps rÃ©el les rÃ©sultats de ces modÃ¨les.


## ğŸ› ï¸ Installation et DÃ©marrage du Projet<a name="installation-et-dÃ©marrage-du-projet"></a>

### PrÃ©requis
- Python 3.11+
- Docker (optionnel)
- AccÃ¨s Ã  Google Cloud Platform (optionnel)

### Ã‰tapes d'Installation

1. **Cloner le dÃ©pÃ´t :**

    ```bash
    git clone https://github.com/keagnon/DetectionAnomalie.git
    ```

2. **Installer les dÃ©pendances :**

    ```bash
    pip install -r requirements.txt
    ```

3. **Configurer l'environnement :**
   - CrÃ©ez un fichier `.env` Ã  la racine du projet pour stocker vos clÃ©s d'API et configurations Google Cloud.

    Exemple de `.env` :

    ```ini
    GCP_STORAGE_BUCKET=my-bucket
    MLFLOW_TRACKING_URI=http://58.36.14.89:5000
    ```

4. **DÃ©marrer MLFlow en local :**

    ```bash
    mlflow ui
    ```

5. **Lancer le projet :**
   Si vous utilisez **Streamlit** pour l'interface utilisateur, exÃ©cutez la commande suivante :

    ```bash
    streamlit run streamlit/interface_meteo.py
    ```

## ğŸ“‚ Structure du Projet<a name="structure-du-projet"></a>

```bash
ğŸ“¦ meteo/
â”œâ”€â”€ ğŸ“ conf/                      # Fichiers de configuration
â”œâ”€â”€ ğŸ“ data/                      # DonnÃ©es utilisÃ©es dans le projet
â”‚   â”œâ”€â”€ ğŸ“ 01_raw/                # DonnÃ©es brutes
â”‚   â”œâ”€â”€ ğŸ“ 02_intermediate/       # DonnÃ©es intermÃ©diaires
â”‚   â”œâ”€â”€ ğŸ“ 03_primary/            # DonnÃ©es primaires nettoyÃ©es
â”‚   â”œâ”€â”€ ğŸ“ 04_feature/            # Features pour les modÃ¨les
â”‚   â”œâ”€â”€ ğŸ“ 05_model_input/        # DonnÃ©es prÃªtes pour les modÃ¨les
â”‚   â”œâ”€â”€ ğŸ“ 06_models/             # ModÃ¨les d'apprentissage automatique
â”‚   â”œâ”€â”€ ğŸ“ 07_model_output/       # RÃ©sultats des modÃ¨les
â”‚   â””â”€â”€ ğŸ“ 08_reporting/          # Rapports et visualisations des rÃ©sultats
â”œâ”€â”€ ğŸ“ docs/                      # Documentation du projet
â”œâ”€â”€ ğŸ“ MeteoMLFLOW/               # Gestion des expÃ©riences ML avec MLFlow
â”œâ”€â”€ ğŸ“ notebooks/                 # Notebooks Jupyter pour l'analyse exploratoire
â”œâ”€â”€ ğŸ“ src/                       # Code source principal
â”‚   â”œâ”€â”€ ğŸ“ meteo/                 # Code spÃ©cifique Ã  la mÃ©tÃ©o
â”‚   â”‚   â”œâ”€â”€ ğŸ“ pipelines/         # Pipelines de traitement
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ data_processing/  # Scripts de traitement des donnÃ©es
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ data_science/     # Scripts liÃ©s aux modÃ¨les
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ data_viz/         # Scripts de visualisation des donnÃ©es
â”œâ”€â”€ ğŸ“ mlflow-artifacts/          # Artifacts gÃ©nÃ©rÃ©s par MLFlow
â”œâ”€â”€ ğŸ“ mlruns/                    # Logs et informations sur les runs MLFlow
â””â”€â”€ ğŸ“ notebooks/                 # Notebooks d'analyse
```


## ğŸš€ FonctionnalitÃ©s Principales<a name="fonctionnalitÃ©s-principales"></a>

- **DÃ©tection d'anomalies** : Identification des anomalies dans la consommation Ã©nergÃ©tique Ã  partir de donnÃ©es mÃ©tÃ©orologiques.
- **ModÃ¨les utilisÃ©s :** CrÃ©ation d'un modÃ¨le de prÃ©diction de la consommation Ã©nergetiques en prenant en compte les conditions mÃ©tÃ©orologique.
- **Streamlit** : Interface utilisateur interactive permettant la visualisation en temps rÃ©el des rÃ©sultats du modÃ¨le.
- **Kedro Pipelines** : Pipelines modulaires pour le traitement de donnÃ©es et l'apprentissage automatique, facilitant la rÃ©utilisation et la gestion des workflows complexes.
- **MLFlow** : Suivi complet des modÃ¨les de machine learning, y compris la versioning, les mÃ©triques et les artefacts.
- **Google Cloud Storage** : Stockage des donnÃ©es et des modÃ¨les pour une collaboration efficace et une mise Ã  l'Ã©chelle.


## ğŸ“ˆ IntÃ©gration avec Kedro et Streamlit<a name="intÃ©gration-avec-kedro-et-streamlit"></a>

### Kedro Pipelines

Dans notre projet, les pipelines Kedro sont utilisÃ©s pour organiser les diffÃ©rentes Ã©tapes de traitement des donnÃ©es, l'entraÃ®nement des modÃ¨les et la gÃ©nÃ©ration de rapports. Chaque pipeline a un rÃ´le spÃ©cifique et s'intÃ¨gre dans l'architecture globale du projet.

#### **Structure des Pipelines dans votre Projet**

La structure de nos pipelines, situÃ©e dans le rÃ©pertoire `src/meteo/pipelines/`, est organisÃ©e comme suit :

```bash
src/meteo/pipelines/
â”œâ”€â”€ data_processing/         # Pipeline pour le traitement et le nettoyage des donnÃ©es
â”œâ”€â”€ data_science/            # Pipeline pour l'entraÃ®nement des modÃ¨les de machine learning
â”œâ”€â”€ data_viz/                # Pipeline pour la visualisation des donnÃ©es
â”œâ”€â”€ reporting/               # Pipeline pour la gÃ©nÃ©ration de rapports
```

#### **Description des Pipelines**

1. **Pipeline `data_processing`** :
   Ce pipeline est chargÃ© du prÃ©traitement des donnÃ©es brutes es donnÃ©es mÃ©tÃ©orologiques et de la consommation journaliÃ¨re. Les tÃ¢ches typiques incluent le nettoyage des donnÃ©es, la gestion des valeurs manquantes et la transformation des donnÃ©es pour qu'elles soient prÃªtes Ã  Ãªtre utilisÃ©es par les modÃ¨les de machine learning.

2. **Pipeline `data_science`** :
   Ce pipeline est dÃ©diÃ© Ã  l'entraÃ®nement et Ã  l'Ã©valuation des modÃ¨les de machine learning. Il inclut l'intÃ©gration des modÃ¨les comme **CatBoost** et **Random Forest**. Les rÃ©sultats des expÃ©riences sont enregistrÃ©s via **MLFlow** pour permettre un suivi complet des versions des modÃ¨les, des mÃ©triques, et des configurations d'entraÃ®nement. L'empreinte carbone des entraÃ®nements est Ã©galement mesurÃ©e via **CodeCarbon** et est stockÃ©e pour analyse.

3. **Pipeline `data_viz`** :
   Le pipeline de visualisation gÃ©nÃ¨re des graphiques et des tableaux de bord pour une meilleure interprÃ©tation des rÃ©sultats des modÃ¨les. Ces visualisations sont souvent utilisÃ©es dans l'interface utilisateur **Streamlit** pour permettre une interaction dynamique avec les donnÃ©es et les rÃ©sultats.

4. **Pipeline `reporting`** :
   Ce pipeline gÃ©nÃ¨re des rapports complets sur les performances des modÃ¨les, incluant des visualisations des mÃ©triques, des comparaisons des rÃ©sultats et des rapports dÃ©taillÃ©s sur les diffÃ©rentes itÃ©rations des modÃ¨les. Ces rapports permettent de suivre les performances et de faciliter la prise de dÃ©cisions sur le choix des modÃ¨les Ã  dÃ©ployer.


### Interface Utilisateur avec Streamlit

L'application **Streamlit** permet de visualiser les rÃ©sultats des modÃ¨les de maniÃ¨re dynamique et interactive. Les utilisateurs peuvent ajuster divers paramÃ¨tres et observer les impacts en temps rÃ©el sur les prÃ©dictions et les visualisations des donnÃ©es.

![Interface Utilisateur Streamlit](images/UI.png)


## ğŸ“Š ModÃ¨les et Algorithmes UtilisÃ©s<a name="modÃ¨les-et-algorithmes-utilisÃ©s"></a>

**CatBoost** et **Random Forest** : EmployÃ© pour la prÃ©diction consommation d'Ã©nergie.

## ğŸ“ˆ IntÃ©gration avec MLFlow<a name="intÃ©gration-avec-mlflow"></a>

Nous utilisons **MLFlow** pour gÃ©rer l'entraÃ®nement et le suivi des modÃ¨les, en garantissant une traÃ§abilitÃ© complÃ¨te des expÃ©riences.

1. **Enregistrement des modÃ¨les :**
   Tous les modÃ¨les sont enregistrÃ©s avec leurs hyperparamÃ¨tres, mÃ©triques et artefacts.

2. **Suivi des versions :**
   MLFlow gÃ¨re la versioning des modÃ¨les, permettant une comparaison facile des performances entre diffÃ©rentes itÃ©rations.

3. **Interface d'accÃ¨s :**
   Un serveur **MLFlow** est mis en place avec **GCP** pour permettre Ã  l'Ã©quipe de suivre et de gÃ©rer les modÃ¨les de maniÃ¨re centralisÃ©e.

![ExpÃ©riences MLFlow](images/mlflow_experiment.png)


## ğŸŒ± Empreinte Carbone avec CodeCarbon<a name="empreinte-carbone-avec-codecarbon"></a>

Le projet intÃ¨gre **CodeCarbon** pour mesurer et rÃ©duire l'empreinte carbone gÃ©nÃ©rÃ©e par l'entraÃ®nement des modÃ¨les. Cette initiative vise Ã  optimiser la consommation Ã©nergÃ©tique pendant les phases de calcul intensif, en suivant les Ã©missions via le fichier de mÃ©triques gÃ©nÃ©rÃ© par CodeCarbon.
.

Le fichier gÃ©nÃ©rÃ© se trouve dans `ml_models/meteo_consommation/meteo/streamlit/emissions.csv`.

![Empreinte Carbone avec CodeCarbon](images/empreinte_carbone.png)