# üìä Anomaly Detection Dashboard (Streamlit)

### Langage

![Python](https://img.shields.io/badge/Python-3.9-blue?style=for-the-badge&logo=python)

### Frameworks et Outils de D√©veloppement

![Streamlit](https://img.shields.io/badge/Streamlit-1.38.0-red?style=for-the-badge&logo=streamlit)
![Flask](https://img.shields.io/badge/Flask-3.0.3-black?style=for-the-badge&logo=flask)
![Docker](https://img.shields.io/badge/Docker-Enabled-blue?style=for-the-badge&logo=docker)

### Machine Learning & Data Science

![MLflow](https://img.shields.io/badge/MLflow-2.16.0-orange?style=for-the-badge&logo=mlflow)
![Pandas](https://img.shields.io/badge/Pandas-2.2.2-green?style=for-the-badge&logo=pandas)
![Scikit-learn](https://img.shields.io/badge/Scikit--Learn-1.5.1-orange?style=for-the-badge&logo=scikit-learn)
![Matplotlib](https://img.shields.io/badge/Matplotlib-3.9.2-blue?style=for-the-badge&logo=matplotlib)
![Plotly](https://img.shields.io/badge/Plotly-5.24.0-blue?style=for-the-badge&logo=plotly)

### Cloud & Stockage

![Boto3](https://img.shields.io/badge/Boto3-1.35.14-005e00?style=for-the-badge&logo=amazonaws)
![Google Cloud Storage](https://img.shields.io/badge/Google%20Cloud%20Storage-2.18.2-orange?style=for-the-badge&logo=googlecloud)

### Librairies pour les Logs

![Elasticsearch](https://img.shields.io/badge/Elasticsearch-8.10.0-005571?style=for-the-badge&logo=elasticsearch)
![psutil](https://img.shields.io/badge/psutil-5.9.7-blue?style=for-the-badge)
![Loguru](https://img.shields.io/badge/Loguru-0.6.0-purple?style=for-the-badge&logo=logstash)

## üìë Introduction

Ce projet est le **tableau de bord final** d√©velopp√© avec **Streamlit** qui englobe toutes les fonctionnalit√©s des diff√©rents mod√®les d√©velopp√©s dans le cadre de notre projet de **d√©tection d'anomalies**. Ce tableau de bord permet d'interagir avec plusieurs mod√®les de machine learning et d'observer leurs performances sur diff√©rentes t√¢ches.

Cette partie de notre projet de **d√©tection d'anomalies** se concentre sur les aspects suivants :

- üìà **D√©tection d'anomalies** pour rep√©rer des comportements anormaux dans les donn√©es.
- üß† **Clustering** pour grouper les donn√©es par r√©gion et mieux comprendre les tendances.
- üîÆ **Pr√©diction de la consommation** d'√©nergie en prenant en compte les conditions m√©t√©orologiques et les mouvements sociaux.
- üìù **Feedback utilisateur** pour am√©liorer les mod√®les en continu.
- üîç **Suivi des r√©sultats** et des m√©triques des mod√®les via **MLflow**.


## üìö Sommaire

1. [üì¶ Installation](#installation)
2. [üöÄ Lancer l'application](#lancer-lapplication)
3. [üìä Fonctionnalit√©s](#fonctionnalit√©s)
   - [üîç D√©tection d'anomalies](#d√©tection-danomalies)
   - [üß† Clustering](#clustering)
   - [üîÆ Pr√©diction de la consommation en prenant en consid√©ration les mouvements sociaux](#pr√©diction-de-la-consommation)
   - [‚òÅÔ∏è Pr√©diction de la cosommation en prenant en compte les conditions m√©t√©orologiques](#pr√©diction-m√©t√©o)
   - [üìù Feedback utilisateur](#feedback-utilisateur)
   - [üìà Suivi des r√©sultats et des mod√®les](#suivi-des-r√©sultats-et-des-mod√®les)
   - [üìä Monitoring et Logs Unifi√©s](#monitoring-et-logs-unifi√©s)
4. [üìÅ Structure du projet](#structure-du-projet)
5. [üñºÔ∏è Captures d'√©cran](#captures-d‚Äô√©cran)


## üì¶ Installation <a name="installation"></a>

Avant de commencer, assurez-vous d'avoir **Python 3.9+** et **Docker** install√©s sur votre machine.

### √âtapes d'installation :

1. **Clonez ce d√©p√¥t :**

   ```bash
   git clone https://github.com/keagnon/DetectionAnomalie.git
   cd DetectionAnomalie
   ```

2. **Installez les d√©pendances :**

   ```bash
   pip install -r requirements.txt
   ```

3. **Configuration des variables d'environnement :**

   Cr√©ez un fichier `.env` et renseignez les informations de connexion, notamment MongoDB et Elasticsearch :

   ```env
    GOOGLE_APPLICATION_CREDENTIALS=chemin/vers/fichier.json
    MLFLOW_TRACKING_URI=url-de-suivi-mlflow
    MLFLOW_ARTEFACTS_LOCATION=gs://votre-bucket/mlflow_experiment
    AWS_ACCESS_KEY=votre-aws-access-key
    AWS_SECRET_KEY=votre-aws-secret-key
    S3_BUCKET_NAME=bucketfeedbacks
    S3_REGION_NAME=eu-west-3
   ```


## üöÄ Lancer l'application <a name="lancer-lapplication"></a>

### Localement avec Python :

```bash
streamlit run app.py
```

### Avec Docker ‚öôÔ∏è :

Le projet est enti√®rement **dockeris√©** pour faciliter le d√©ploiement dans diff√©rents environnements.

1. **Construisez l'image Docker :**

   ```bash
   docker build -t anomaly-dashboard .
   ```

2. **Ex√©cutez le conteneur Docker :**

   ```bash
   docker run -p 8501:8501 --env-file .env anomaly-dashboard
   ```

Acc√©dez √† l'application via [http://localhost:8501](http://localhost:8501).


## üìä Fonctionnalit√©s <a name="fonctionnalit√©s"></a>

### üîç D√©tection d'anomalies <a name="d√©tection-danomalies"></a>

La section **d√©tection d'anomalies** utilise des mod√®les comme **Isolation Forest** pour d√©tecter des comportements anormaux dans les donn√©es de consommation. Lorsque des donn√©es sont charg√©es via l'interface, un tableau s'affiche avec les donn√©es charg√©es. Les anomalies sont soulign√©es en <span style="color:red">rouge</span>.

![D√©tection d'anomalies](images/anomaly_detection/anomaly1.png)

### üß† Clustering <a name="clustering"></a>

Dans cette section, nous utilisons des algorithmes de clustering tels que **DBSCAN** et **K-means** pour regrouper les donn√©es en clusters distincts. L'utilisateur peut charger des donn√©es via notre interface, visualiser les clusters et analyser les tendances.

![Clustering](images/clustering/clustering1.png)

### üîÆ Pr√©diction de la consommation prise en compte des mouvements sociaux <a name="pr√©diction-de-la-consommation"></a>

Cette section permet de tester et de visualiser les r√©sultats de diff√©rents mod√®les de pr√©diction de la consommation √©nerg√©tique.

![Pr√©diction de la consommation](images/prediction_conso/im1.png)

### ‚òÅÔ∏è Pr√©diction de la consommation prise en compte m√©t√©o <a name="pr√©diction-m√©t√©o"></a>

Similaire √† la pr√©diction de la consommation, cette section utilise des mod√®les pour pr√©dire la consommation en pr√©nant en compte les conditions m√©t√©orologiques.

![Pr√©diction m√©t√©o](images/prediction_conso_meteo/meteo1.png)

### üìù Feedback utilisateur <a name="feedback-utilisateur"></a>

Cette section permet aux utilisateurs d'envoyer des retours sur les pr√©dictions et les anomalies d√©tect√©es. Les retours utilisateurs sont stock√©s dans **Aws** et utilis√©s pour am√©liorer les mod√®les.

![Feedback](images/feedback/feedback1-1.png)

### üìà Suivi des r√©sultats et des mod√®les <a name="suivi-des-r√©sultats-et-des-mod√®les"></a>

Le suivi des r√©sultats est effectu√© avec **MLflow**, qui permet de visualiser les performances des mod√®les, de comparer les diff√©rentes versions, et de suivre l'historique des exp√©riences via une interface d√©di√©e. Au clic sur l'onglet  **Tracking**, vous serez rediriger vers notre serveur Mlflow mis en place pour notre √©quipe.

![Suivi des r√©sultats](images/tracking/whenclickingMlflowonMenuUI.png)

## üìä Monitoring et Logs Unifi√©s <a name="monitoring-et-logs-unifi√©s></a>

Dans cette section, nous d√©taillons le processus de **monitoring** des diff√©rentes fonctionnalit√©s de l'application en utilisant **Elasticsearch** et un tableau de bord de suivi. Chaque action (d√©tection d'anomalies, clustering, pr√©dictions, etc.) est logg√©e dans un format unifi√©. Les logs sont envoy√©s √† **Elasticsearch** et ensuite visualis√©s dans un tableau de bord de monitoring.

### Structure des Logs Unifi√©s

Les logs sont envoy√©s √† **Elasticsearch** avec une structure coh√©rente pour chaque action. Voici la structure de base d'un log unifi√© :

```json
{
    "timestamp": "2024-09-17T10:12:34.123Z",
    "event": "model_execution",
    "model_name": "IsolationForest",
    "model_version": "1.0.0",
    "application_name": "AnomalyDetectionApp",
    "response_time": 1.345,
    "log_level": "INFO",
    "status": "completed",
    "cpu_usage": 15.2,
    "memory_usage": 62.5,
    "details": {
        "anomalies_count": 5,
        "noise_points_count": 2,
        "successful_predictions": 10,
        "failed_predictions": 1,
        "inputs": {
            "region": "√éle-de-France",
            "social_movement": 1,
            "month": 9,
            "day_of_week": 2
        }
    }
}
```
### Explication des champs de log

- **timestamp** : Le moment o√π l'action a eu lieu.
- **event** : Le type d'√©v√©nement enregistr√© (exemple : `model_execution`).
- **model_name** : Le mod√®le utilis√© pour l'action (exemple : `IsolationForest`).
- **model_version** : La version du mod√®le utilis√©.
- **application_name** : L'application qui g√©n√®re le log (exemple : `AnomalyDetectionApp`).
- **response_time** : Temps de r√©ponse en secondes pour l'ex√©cution de l'√©v√©nement.
- **log_level** : Niveau du log (exemple : `INFO` pour succ√®s, `ERROR` pour √©chec).
- **status** : Statut de l'ex√©cution (`completed` ou `failed`).
- **cpu_usage** et **memory_usage** : Utilisation des ressources syst√®me au moment de l'√©v√©nement.
- **details** : Contient des informations sp√©cifiques √† l'√©v√©nement, comme les **inputs** de l'utilisateur et les r√©sultats de l'ex√©cution.

---

### Explication des logs par type d'√©v√©nement

- **D√©tection d'anomalies** : Le log enregistre le nombre d'anomalies d√©tect√©es, le nombre de pr√©dictions r√©ussies et √©chou√©es, ainsi que les entr√©es sp√©cifiques √† l'utilisateur.
- **Clustering** : Le log contient des informations sur le nombre de clusters d√©tect√©s et les points consid√©r√©s comme du bruit.
- **Pr√©diction de consommation √©nerg√©tique (m√©t√©o ou mouvements sociaux)** : Chaque log inclut les **inputs** de l'utilisateur, tels que la r√©gion, la plage horaire et le mouvement social, ainsi que la consommation √©nerg√©tique pr√©dite.

Voici une capture d'√©cran de l'interface d'**Elasticsearch** montrant les logs unifi√©s et les diff√©rents √©v√©nements enregistr√©s dans l'application :
![Elasticsearch Logs](images/monitoring/im1.png)

### Tableau de Bord de Monitoring

Nous avons mis en place un **tableau de bord** dans **Kibana** pour visualiser les logs en temps r√©el et suivre les performances des diff√©rents mod√®les. Voici les m√©triques suivies sur ce tableau de bord :

- **CPU et M√©moire** : Suivi de l'utilisation des ressources syst√®me lors des pr√©dictions.
- **Temps de r√©ponse** : Affichage des temps de r√©ponse des diff√©rents mod√®les.
- **Statut des Ex√©cutions** : Nombre de pr√©dictions r√©ussies et √©chou√©es.
- **Analyse des Anomalies** : Nombre d'anomalies d√©tect√©es par r√©gion.

Voici une capture d'√©cran du **tableau de bord Kibana** avec les diff√©rentes m√©triques suivies :
![Kibana Dashboard](path_to_screenshot_kibana_dashboard.png)

## üìÅ Structure du projet <a name="structure-du-projet"></a>

Voici un aper√ßu de la structure du projet :

```bash
dashboard_ui/
‚îÇ
‚îú‚îÄ‚îÄ app.py                      # Point d'entr√©e principal pour Streamlit
‚îú‚îÄ‚îÄ Dockerfile                   # Fichier Docker pour le d√©ploiement
‚îú‚îÄ‚îÄ requirements.txt             # D√©pendances Python
‚îú‚îÄ‚îÄ .env                         # Fichier des variables d'environnement (non inclus dans Git)
‚îú‚îÄ‚îÄ styles.css                   # Styles CSS pour l'application
‚îÇ
‚îú‚îÄ‚îÄ page_anomalie_detection.py    # Page de d√©tection d'anomalies
‚îú‚îÄ‚îÄ page_clustering.py            # Page de clustering
‚îú‚îÄ‚îÄ page_feedback.py              # Page pour les retours utilisateur
‚îú‚îÄ‚îÄ page_prediction_conso.py      # Page pour les pr√©dictions de consommation
‚îú‚îÄ‚îÄ page_prediction_meteo.py      # Page pour les pr√©dictions m√©t√©o
‚îú‚îÄ‚îÄ page_tracking.py              # Page pour le suivi des r√©sultats avec MLflow
‚îú‚îÄ‚îÄ utils.py                      # Module utilitaire pour les fonctions r√©utilisables dans l'application
‚îÇ
‚îú‚îÄ‚îÄ mlruns/                       # R√©pertoire de suivi MLflow
‚îî‚îÄ‚îÄ dashboard_ui_streamlit/        # Fichiers et assets suppl√©mentaires
```


## üñºÔ∏è Captures d'√©cran <a name="captures-d‚Äô√©cran"></a>

1. **D√©tection d'anomalies**

   ![D√©tection d'anomalies](images/anomaly_detection/anomaly1.png)
   ![D√©tection d'anomalies](images/anomaly_detection/anomaly2.png)
   ![D√©tection d'anomalies](images/anomaly_detection/anomaly3.png)
   ![D√©tection d'anomalies](images/anomaly_detection/anomaly_mlflow_communication.png)
   ![D√©tection d'anomalies](images/anomaly_detection/anomaly4.png)
   ![D√©tection d'anomalies](images/anomaly_detection/anomaly5.png)
   ![D√©tection d'anomalies](images/anomaly_detection/anomaly6.png)
   ![D√©tection d'anomalies](images/anomaly_detection/anomaly7.png)

2. **Clustering**

   ![Clustering](images/clustering/clustering1.png)
   ![Clustering](images/clustering/clustering2.png)
   ![Clustering](images/clustering/clustering3.png)
   ![Clustering](images/clustering/clustering_mlflow_communication.png)

3. **Pr√©diction de la consommation prise en compte des mouvements sociaux**

   ![Pr√©diction de la consommation](images/prediction_conso/im1.png)
   ![Pr√©diction de la consommation](images/prediction_conso/im2.png)
   ![Pr√©diction de la consommation](images/prediction_conso/im3.png)

4. **Pr√©diction de la consommation prise en compte m√©t√©o**

   ![Pr√©diction m√©t√©o](images/prediction_conso_meteo/meteo1.png)

5. **Feedback utilisateur**

   ![Feedback utilisateur](images/feedback/feedback1-1.png)
   ![Feedback utilisateur](images/feedback/feedback1.png)
   ![Feedback utilisateur](images/feedback/feedback2.png)
   ![Feedback utilisateur](images/feedback/feedback3.png)
   ![Feedback utilisateur](images/feedback/feedback_store_aws.png)
   ![Feedback utilisateur](images/feedback/list_feedback_store_aws.png)

6. **Suivi des r√©sultats**

   ![Suivi des r√©sultats](images/tracking/mlflow_trackin.png)
   ![Suivi des r√©sultats](images/tracking/whenclickingMlflowonMenuUI.png)

7. **Elasticsearch**

   ![Elasticsearch Logs](images/monitoring/im1.png)
   ![Elasticsearch Logs](images/monitoring/im1.png)

8. **Tableau de Bord des logs avec Kibana**

   ![Kibana Dashboard](path_to_screenshot_kibana_dashboard.png)




