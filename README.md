# ğŸš€ DÃ©tection d'Anomalies dans la Consommation d'Ã‰nergie

### Langage

![Python Badge](https://img.shields.io/badge/python-3.9-blue)

### Frameworks et Outils de DÃ©veloppement

![Streamlit Badge](https://img.shields.io/badge/Streamlit-1.38.0-orange)
![MLFlow Badge](https://img.shields.io/badge/MLFlow-2.16.0-orange)
![Flask Badge](https://img.shields.io/badge/Flask-3.0.3-black)
![Docker Badge](https://img.shields.io/badge/Docker-Enabled-blue)
![Kedro Badge](https://img.shields.io/badge/Kedro-0.19.8-brightgreen)
![Pre-commit Badge](https://img.shields.io/badge/Pre--Commit--Hooks-4.6.0-blue)
![GitPython Badge](https://img.shields.io/badge/GitPython-3.1.43-orange)

### Machine Learning & Data Science

![MLFlow Badge](https://img.shields.io/badge/MLFlow-2.16.0-orange)
![Pandas Badge](https://img.shields.io/badge/Pandas-2.2.2-brightgreen)
![Scikit-Learn Badge](https://img.shields.io/badge/Scikit--learn-1.5.1-orange)
![Matplotlib Badge](https://img.shields.io/badge/Matplotlib-3.9.2-blue)
![Plotly Badge](https://img.shields.io/badge/Plotly-5.24.0-blue)
![KMeans Badge](https://img.shields.io/badge/KMeans-Clustering-yellow)
![DBSCAN Badge](https://img.shields.io/badge/DBSCAN-Clustering-brightgreen)
![Isolation Forest Badge](https://img.shields.io/badge/Isolation--Forest-Anomaly%20Detection-blue)
![Ridge Regression Badge](https://img.shields.io/badge/Ridge--Regression-Prediction-lightblue)
![Random Forest Badge](https://img.shields.io/badge/Random--Forest-Prediction-brightgreen)

### Cloud & Stockage

![Google Cloud Storage Badge](https://img.shields.io/badge/Google%20Cloud%20Storage-2.18.2-orange)
![Elasticsearch Badge](https://img.shields.io/badge/Elasticsearch-8.15.0-grey)
![PyMongo Badge](https://img.shields.io/badge/PyMongo-4.8.0-green)
![Boto3 Badge](https://img.shields.io/badge/Boto3-1.35.14-green)

### CI/CD et Outils de DÃ©bogage

![Pre-Commit Badge](https://img.shields.io/badge/Pre--Commit--Hooks-4.6.0-blue)
![Pylint Badge](https://img.shields.io/badge/Pylint-Enabled-green)
![Isort Badge](https://img.shields.io/badge/Isort-Enabled-brightgreen)
![Black Badge](https://img.shields.io/badge/Black-Enabled-black)
![GitHub Actions Badge](https://img.shields.io/badge/GitHub--Actions-CI%2FCD-brightgreen)


## ğŸ“‘ Sommaire
1. [ğŸ” Contexte du Projet](#contexte-du-projet)
2. [ğŸ¯ Pourquoi ce projet ?](#pourquoi-ce-projet)
3. [ğŸ¯ Objectifs du Projet](#objectifs-du-projet)
4. [ğŸ—ï¸ Architecture du Projet](#architecture-du-projet)
5. [âš™ï¸ IntÃ©gration Continue (CI) et Tests Unitaires](#intÃ©gration-continue-ci-et-tests-unitaires)
6. [ğŸ“‚ Structure du Projet](#structure-du-projet)
7. [ğŸ”„ Pipelines de Collecte de DonnÃ©es avec Kedro](#pipelines-de-collecte-de-donnÃ©es-avec-kedro)
8. [ğŸ’» Traitement des DonnÃ©es et Utilisation de Google Colab](#traitement-des-donnÃ©es-et-utilisation-de-google-colab)
9. [ğŸ¤– ModÃ¨les de Machine Learning](#modÃ¨les-de-machine-learning)
10. [ğŸ–¥ï¸ Interface Utilisateur avec Streamlit](#interface-utilisateur-avec-streamlit)
11. [ğŸ“Š Ordonnancement des DonnÃ©es avec Airflow](#ordonnancement-des-donnÃ©es-avec-airflow)
12. [ğŸ“œ Conclusion](#conclusion)
13. [âš ï¸ DifficultÃ©s RencontrÃ©es](#difficultÃ©s_rencontrÃ©es)
14. [ğŸš€ Prochaines Ã‰tapes : Phase 2 - Forecasting ](#prochaine_etapes)



## 1. ğŸ” Contexte du Projet<a name="contexte-du-projet"></a>
La dÃ©tection prÃ©coce des anomalies Ã©nergÃ©tiques est essentielle pour la gestion proactive de l'Ã©nergie, en particulier pendant les pÃ©riodes de forte demande (hiver, Ã©tÃ©) ou durant des Ã©vÃ©nements comme les mouvements sociaux. Ce projet vise Ã  identifier ces anomalies en se basant sur des donnÃ©es variÃ©es (mÃ©tÃ©orologiques, sociales, etc.) et Ã  fournir une interface utilisateur permettant la visualisation et l'analyse des rÃ©sultats. La solution est structurÃ©e en plusieurs sous-projets interconnectÃ©s, chacun avec des objectifs spÃ©cifiques.

## 2. ğŸ¯ Pourquoi ce projet ? <a name="pourquoi-ce-projet"></a>
Nous avons identifiÃ© plusieurs dÃ©fis majeurs dans la gestion Ã©nergÃ©tique :
- **Surconsommation en Hiver et en Ã‰tÃ©** : Augmentation significative de la demande en Ã©lectricitÃ© pendant les pÃ©riodes de froid ou de chaleur extrÃªme.
- **Jours FÃ©riÃ©s et Mouvements Sociaux** : Les variations imprÃ©vues dans la consommation peuvent dÃ©sÃ©quilibrer l'offre et la demande.

Nos cibles principales incluent :
- **Entreprises d'Ã‰lectricitÃ©** (comme Engie et EDF) qui doivent surveiller la consommation en temps rÃ©el et ajuster leur production.
- **Industries Ã  Forte Consommation** qui nÃ©cessitent une gestion optimale de leur Ã©nergie pour Ã©viter des interruptions.

## 3. ğŸ¯ Objectifs du Projet <a name="objectifs-du-projet"></a>
Notre projet se concentre sur six grands objectifs :
1. **ğŸ” DÃ©tection des Anomalies** : Identifier en temps rÃ©el les anomalies de consommation et les cyberattaques potentielles.
2. **ğŸ“ˆ PrÃ©diction des Incidents** : Utiliser des modÃ¨les prÃ©dictifs pour anticiper les risques futurs.
3. **âš¡ Optimisation des Ressources** : Aider les entreprises Ã  optimiser leur consommation Ã©nergÃ©tique.
4. **ğŸ”„ AmÃ©lioration Continue** : IntÃ©grer les retours des utilisateurs pour perfectionner notre systÃ¨me.
5. **ğŸŒ RÃ©duction de l'Empreinte Carbone** : Calculer l'impact carbone de nos serveurs et de nos traitements de donnÃ©es.
6. **ğŸ“… PrÃ©vision et Planification** : Utiliser des sÃ©ries temporelles pour prÃ©dire les besoins futurs en Ã©nergie.

## 4. ğŸ—ï¸ Architecture du Projet <a name="architecture-du-projet"></a>
Le projet est divisÃ© en plusieurs modules interconnectÃ©s, chacun jouant un rÃ´le clÃ© dans l'ensemble du systÃ¨me.

- **ğŸ› ï¸ Module Collecte et Stockage des DonnÃ©es**
- **ğŸ› ï¸ Module Traitement, Stockage et Visualisation**
- **ğŸ› ï¸ Module EntraÃ®nement et Suivi des ModÃ¨les**
- **ğŸ› ï¸ Module DÃ©ploiement et Feedback**
- **ğŸ› ï¸ Module d'Orchestration et Conteneurisation**
- **ğŸ› ï¸ Module IntÃ©gration Continue (CI) et Tests Unitaires**

![Workflow_gÃ©neral](images/Workflow.png)

## 5. âš™ï¸ IntÃ©gration Continue (CI) et Tests Unitaires <a name="intÃ©gration-continue-ci-et-tests-unitaires"></a>
Nous avons mis en place une CI via GitHub Actions, qui exÃ©cute des tests unitaires pour chaque sous-projet Ã  chaque commit.

### Outils utilisÃ©s pour la CI :
- **ğŸ§ª Pytest** pour les tests unitaires
- **ğŸ” Pylint, Black, Mypy** pour l'analyse statique et le formatage du code
- **ğŸ“Š Coverage** pour mesurer la couverture des tests

Le pipeline de CI est disponible dans le rÃ©pertoire `.github/workflows`.

Chaque module du projet est containerisÃ© avec Docker pour garantir la portabilitÃ© et la cohÃ©rence des environnements. Les fichiers `.env` sont utilisÃ©s pour configurer les variables d'environnement de maniÃ¨re flexible.

## 6. ğŸ“‚ Structure du Projet <a name="structure-du-projet"></a>
(InsÃ©rer la structure dÃ©taillÃ©e du projet ici)

Nous utilisons un **ğŸ› ï¸ Makefile** pour automatiser les processus de build, de tests et faciliter la gestion de la CI locale.

## 7. ğŸ”„ Pipelines de Collecte de DonnÃ©es avec Kedro <a name="pipelines-de-collecte-de-donnÃ©es-avec-kedro"></a>
Cette partie est un sous projet dÃ©velopper pour la partie ingestion des donnÃ©es est inclus dans notre projet de dÃ©tection d'anomalie .
Deux pipelines Kedro ont Ã©tÃ© mis en place :
1. **Pipeline ETL** : Ce pipeline collecte, transforme et stocke les donnÃ©es dans MongoDB.
2. **Pipeline d'Enrichissement** : Ce pipeline charge les donnÃ©es, les fusionne et les stocke dans Elasticsearch.

Pour accÃ©der Ã  ce sous projet et Ã voir plus de dÃ©tails, consultez le [README de la partie Kedro](https://github.com/keagnon/DetectionAnomalie/blob/grace_clustering_mvt/data-collection-kedro/README.md).


## 8. ğŸ’» Traitement des DonnÃ©es et Utilisation de Google Colab <a name="traitement-des-donnÃ©es-et-utilisation-de-google-colab"></a>
Certaines donnÃ©es volumineuses ont Ã©tÃ© traitÃ©es avec **Google Colab**, notamment pour les membres de l'Ã©quipe ayant des limitations matÃ©rielles. Voici une capture d'Ã©cran de nos notebooks sur Google Colab ainsi que notre bucket GCP pour le stockage des donnÃ©es et artefacts. Nous

 utilisons MLflow pour le tracking de nos modÃ¨les :

![Capture du Bucket GCP](images/bucket.png)
![Capture google colab GCP](images/google_colab.png)

## 9. ğŸ¤– ModÃ¨les de Machine Learning <a name="modÃ¨les-de-machine-learning"></a>
Les donnÃ©es ont Ã©tÃ© divisÃ©es en deux groupes :
1. **Consommation journaliÃ¨re par rÃ©gion avec donnÃ©es mÃ©tÃ©orologiques**.
2. **Consommation journaliÃ¨re et mouvements sociaux** (avec une colonne "mouvement social" indiquant les jours avec des Ã©vÃ©nements).

Ces deux groupes de donnÃ©es ont conduit Ã  deux sous-projets distincts :
- [Sous-projet sur la consommation rÃ©gionale et les donnÃ©es mÃ©tÃ©o](lien_readme_conso_meteo).
- [Sous-projet sur la consommation et les mouvements sociaux](https://github.com/keagnon/DetectionAnomalie/blob/grace_clustering_mvt/ml_models/mouvements_consommation/Readme.md).

Ces sous-projets, ainsi que notre interface Streamlit, utilisent **MLflow** pour le suivi et la mise en production des modÃ¨les. Un serveur **MLFlow** a Ã©tÃ© dÃ©ployÃ© sur une VM GCP pour permettre Ã  l'Ã©quipe de suivre les performances des modÃ¨les.

## 10. ğŸ–¥ï¸ Interface Utilisateur avec Streamlit <a name="interface-utilisateur-avec-streamlit"></a>
L'interface utilisateur finale a Ã©tÃ© dÃ©veloppÃ©e avec **Streamlit**. Elle permet :
- Le tÃ©lÃ©chargement de datasets.
- La visualisation des rÃ©sultats des modÃ¨les de machine learning.
- La collecte de feedbacks utilisateurs.

![First_page_dashboard_ui](images/dashboard/first_page.png)

Cette interface est un sous projet de notre projet de dÃ©tection d'anomalie.Il est dÃ©ployÃ©e localement et sur **Streamlit Community**. Pour accÃ©der Ã  ce sous projet et avoir plus de dÃ©tails,cliquer sur [README de lâ€™interface Streamlit](https://github.com/keagnon/DetectionAnomalie/blob/grace_clustering_mvt/dashboard_ui/Readme.md).

## 11. ğŸ“Š Ordonnancement des DonnÃ©es avec Airflow <a name="ordonnancement-des-donnÃ©es-avec-airflow"></a>
Nous avons documentÃ© plusieurs Ã©tapes critiques du projet :
1. **Mise en place dâ€™un serveur MLFlow sur GCP** : [documentation_mlflow](https://github.com/keagnon/DetectionAnomalie/blob/grace_clustering_mvt/documentation/etapes_mise_en_place.pdf)
2. **Mise en place dâ€™un serveur Airflow en local** : [documentation_airflow](https://github.com/keagnon/DetectionAnomalie/blob/grace_clustering_mvt/documentation/etapes_installation_airflow.txt)
3. **Ordonnancement des DonnÃ©es avec Airflow** : [documentation_airflow](https://github.com/keagnon/DetectionAnomalie/blob/grace_clustering_mvt/documentation/Ordonnoncements_donn%C3%A9es.pdf)

**Airflow** est utilisÃ© pour orchestrer les pipelines de collecte de donnÃ©es via des DAGs. Un exemple de DAG est utilisÃ© pour enrichir nos datasets avec des donnÃ©es d'API. Ce script Airflow s'exÃ©cute chaque jour Ã  20h pour une durÃ©e de 30 minutes. Voici des images de notre DAG et de notre interface Airflow :

![Capture dag airflow](images/airflow/im1.png)
![Capture dag airflow](images/airflow/im2.png)
![Capture dag airflow](images/airflow/im3.png)


## 12. ğŸ“œ Conclusion <a name="conclusion"></a>
Le projet de dÃ©tection d'anomalies dans la consommation d'Ã©nergie a permis de mettre en place une solution complÃ¨te, modulaire et scalable. GrÃ¢ce Ã  l'intÃ©gration de diverses technologies comme Kedro, MLflow, Elasticsearch, et Streamlit, nous avons rÃ©ussi Ã  dÃ©velopper un systÃ¨me robuste capable d'identifier des anomalies dans les donnÃ©es de consommation Ã©nergÃ©tique. En combinant des donnÃ©es mÃ©tÃ©orologiques, sociales et de consommation, nous avons pu gÃ©nÃ©rer des insights prÃ©cieux qui aident les entreprises Ã  optimiser leur utilisation d'Ã©nergie.

## 13. âš ï¸ DifficultÃ©s RencontrÃ©es <a name="difficultÃ©s_rencontrÃ©es"></a>
MalgrÃ© les succÃ¨s obtenus, plusieurs dÃ©fis ont Ã©tÃ© rencontrÃ©s au cours du projet :
- **Traitement de DonnÃ©es Volumineuses** : GÃ©rer et traiter des datasets volumineux, en particulier ceux des prÃ©visions mÃ©tÃ©orologiques et des mouvements sociaux, a posÃ© des problÃ¨mes de performance sur certaines machines locales. L'utilisation de Google Colab et GCP a permis de pallier ces limitations. Lors de la collecte des donnÃ©es avec Kedro, nous avons Ã©tÃ© obligÃ©s de stocker les donnÃ©es par lots (batch size) pour pallier ces contraintes, et mÃªme aprÃ¨s la fusion des donnÃ©es, nous avons dÃ» insÃ©rer les donnÃ©es fusionnÃ©es dans Elasticsearch par petits morceaux (chunks).
- **IntÃ©gration de Technologies Diverses** : Le projet a nÃ©cessitÃ© l'intÃ©gration de plusieurs outils et frameworks (Kedro, MLflow, Docker, Elasticsearch), ce qui a parfois entraÃ®nÃ© des difficultÃ©s de compatibilitÃ© et de gestion des dÃ©pendances. La mise en place du serveur MLflow a Ã©galement posÃ© des dÃ©fis techniques.
- **DisponibilitÃ© des DonnÃ©es** : Nous avons dÃ» collecter des donnÃ©es provenant de diffÃ©rentes sources, comme des fichiers PDF, des captures d'Ã©cran, et des fichiers XML, pour crÃ©er un dataset complet. Cela a entraÃ®nÃ© des difficultÃ©s lors de la fusion des donnÃ©es, car certaines dates ne correspondaient pas, et nous Ã©tions en manque rÃ©el de donnÃ©es pour certaines pÃ©riodes.
- **ProblÃ¨mes de Budget** : Le manque de crÃ©dits GCP a Ã©galement Ã©tÃ© un obstacle majeur, car certaines solutions Ã©taient dÃ©ployÃ©es sur des environnements "on-premise", ce qui a limitÃ© l'ampleur de nos expÃ©rimentations.

## 14. ğŸš€ Prochaines Ã‰tapes : Phase 2 - Forecasting <a name="prochaine_etapes"></a>
La prochaine Ã©tape du projet est de passer Ã  la **Phase 2 : Forecasting**. Nous avons pour objectif d'Ã©tendre le systÃ¨me actuel pour inclure des modÃ¨les de prÃ©vision basÃ©s sur des sÃ©ries temporelles, afin d'anticiper les incidents futurs en se basant sur des donnÃ©es historiques et actuelles.

### Objectifs de la Phase 2 :
- **PrÃ©diction des Risques d'Incidents** : PrÃ©dire les risques d'incidents sur une pÃ©riode de 2 Ã  3 mois.
- **Anticipation des Impacts** : Anticiper les impacts des conditions mÃ©tÃ©orologiques et des Ã©vÃ©nements sociaux sur la consommation Ã©nergÃ©tique.
- **Optimisation de la Planification** : Aider les entreprises Ã  planifier et Ã  ajuster leurs stratÃ©gies en fonction des prÃ©visions.

### DÃ©tails :
Nous avons dÃ©jÃ  rÃ©alisÃ© un Proof of Concept (PoC), et l'objectif sera de rendre le systÃ¨me capable d'effectuer des prÃ©visions prÃ©cises et pertinentes. En combinant les donnÃ©es de sÃ©ries temporelles avec les informations sur la consommation et les Ã©vÃ©nements extÃ©rieurs, nous pourrons proposer des prÃ©visions plus prÃ©cises aux entreprises pour les aider Ã  optimiser leurs ressources et Ã©viter les incidents Ã©nergÃ©tiques.

Le systÃ¨me actuel est conÃ§u de maniÃ¨re modulaire, ce qui permettra une transition fluide vers cette phase de forecasting et facilitera l'adaptation continue aux besoins changeants des entreprises et du marchÃ©.
