# üöÄ D√©tection d'Anomalies dans la Consommation d'√ânergie

### Langage

![Python Badge](https://img.shields.io/badge/python-3.9-blue)

### Frameworks et Outils de D√©veloppement

![Streamlit Badge](https://img.shields.io/badge/Streamlit-1.38.0-orange)
![MLFlow Badge](https://img.shields.io/badge/MLFlow-2.16.0-orange)
![Flask Badge](https://img.shields.io/badge/Flask-3.0.3-black)
![Docker Badge](https://img.shields.io/badge/Docker-Enabled-blue)
![Kedro Badge](https://img.shields.io/badge/Kedro-0.19.8-brightgreen)
![Pre-commit Badge](https://img.shields.io/badge/Pre--Commit--Hooks-4.6.0-blue)
![GitPython Badge](https://img.shields.io/badge/GitPython-3.1.43-orange)

### Empreinte Carbone

![CodeCarbon](https://img.shields.io/badge/CODECARBON-v1.2.0-brightgreen)

### Machine Learning & Data Science

![MLFlow Badge](https://img.shields.io/badge/MLFlow-2.16.0-orange)
![Pandas Badge](https://img.shields.io/badge/Pandas-2.2.2-brightgreen)
![Scikit-Learn Badge](https://img.shields.io/badge/Scikit--learn-1.5.1-orange)
![Matplotlib Badge](https://img.shields.io/badge/Matplotlib-3.9.2-blue)
![Plotly Badge](https://img.shields.io/badge/Plotly-5.24.0-blue)
![KMeans Badge](https://img.shields.io/badge/KMeans-Clustering-yellow)
![DBSCAN Badge](https://img.shields.io/badge/DBSCAN-Clustering-brightgreen)
![Isolation Forest Badge](https://img.shields.io/badge/Isolation--Forest-Anomaly%20Detection-blue)
![Ridge Regression Badge](https://img.shields.io/badge/Ridge--Regression-Prediction-lightblue)
![Random Forest Badge](https://img.shields.io/badge/Random--Forest-Prediction-brightgreen)

### Cloud & Stockage

![Google Cloud Storage Badge](https://img.shields.io/badge/Google%20Cloud%20Storage-2.18.2-orange)
![Elasticsearch Badge](https://img.shields.io/badge/Elasticsearch-8.15.0-grey)
![PyMongo Badge](https://img.shields.io/badge/PyMongo-4.8.0-green)
![Boto3 Badge](https://img.shields.io/badge/Boto3-1.35.14-green)

### CI/CD et Outils de D√©bogage

![Pre-Commit Badge](https://img.shields.io/badge/Pre--Commit--Hooks-4.6.0-blue)
![Pytest](https://img.shields.io/badge/Pytest-8.3.2-blue)
![Mypy](https://img.shields.io/badge/Mypy-1.11.2-blue)
![Black](https://img.shields.io/badge/Black-23.11.0-black)
![Python](https://img.shields.io/badge/Python-3.11.5-blue)
![GitHub Actions Badge](https://img.shields.io/badge/GitHub--Actions-CI%2FCD-brightgreen)


## üìë Sommaire
1. [üîç Contexte du Projet](#contexte-du-projet)
2. [üéØ Pourquoi ce projet ?](#pourquoi-ce-projet)
3. [üéØ Objectifs du Projet](#objectifs-du-projet)
4. [üèóÔ∏è Architecture du Projet](#architecture-du-projet)
5. [‚öôÔ∏è Int√©gration Continue (CI) et Tests Unitaires](#int√©gration-continue-ci-et-tests-unitaires)
6. [üåç Calcul de l'Empreinte Carbone du Projet](#co2)
7. [üìÇ Structure du Projet](#structure-du-projet)
8. [üîÑ Pipelines de Collecte de Donn√©es avec Kedro](#pipelines-de-collecte-de-donn√©es-avec-kedro)
9. [üíª Traitement des Donn√©es et Utilisation de Google Colab](#traitement-des-donn√©es-et-utilisation-de-google-colab)
10. [ü§ñ Mod√®les de Machine Learning](#mod√®les-de-machine-learning)
11. [üñ•Ô∏è Interface Utilisateur](#interface-utilisateur-avec-streamlit)
12. [üìä Ordonnancement des Donn√©es](#ordonnancement-des-donn√©es-avec-airflow)
13. [üìú Conclusion](#conclusion)
14. [‚ö†Ô∏è Difficult√©s Rencontr√©es](#difficult√©s_rencontr√©es)
15. [üöÄ Prochaines √âtapes : Phase 2 - Forecasting ](#prochaine_etapes)



## 1. üîç Contexte du Projet<a name="contexte-du-projet"></a>
La d√©tection pr√©coce des anomalies √©nerg√©tiques est essentielle pour la gestion proactive de l'√©nergie, en particulier pendant les p√©riodes de forte demande (hiver, √©t√©) ou durant des √©v√©nements comme les mouvements sociaux. Ce projet vise √† identifier ces anomalies en se basant sur des donn√©es vari√©es (m√©t√©orologiques, sociales, etc.) et √† fournir une interface utilisateur permettant la visualisation et l'analyse des r√©sultats. La solution est structur√©e en plusieurs sous-projets interconnect√©s, chacun avec des objectifs sp√©cifiques.


## 2. üéØ Pourquoi ce projet ? <a name="pourquoi-ce-projet"></a>
Nous avons identifi√© plusieurs d√©fis majeurs dans la gestion √©nerg√©tique :
- **Surconsommation en Hiver et en √ât√©** : Augmentation significative de la demande en √©lectricit√© pendant les p√©riodes de froid ou de chaleur extr√™me.
- **Jours F√©ri√©s et Mouvements Sociaux** : Les variations impr√©vues dans la consommation peuvent d√©s√©quilibrer l'offre et la demande.

Nos cibles principales incluent :
- **Entreprises d'√âlectricit√©** (comme Engie et EDF) qui doivent surveiller la consommation en temps r√©el et ajuster leur production.
- **Industries √† Forte Consommation** qui n√©cessitent une gestion optimale de leur √©nergie pour √©viter des interruptions.

## 3. üéØ Objectifs du Projet <a name="objectifs-du-projet"></a>
Notre projet se concentre sur six grands objectifs :
1. **üîç D√©tection des Anomalies** : Identifier en temps r√©el les anomalies de consommation.
2. **üìà Pr√©diction de la consommation** : Utiliser des mod√®les pr√©dictifs pour pr√©dire la consommation.
3. **‚ö° Optimisation des Ressources** : Aider les entreprises √† optimiser leur consommation √©nerg√©tique.
4. **üîÑ Am√©lioration Continue** : Int√©grer les retours des utilisateurs pour perfectionner notre syst√®me.
5. **üåç R√©duction de l'Empreinte Carbone** : Calculer l'impact carbone de nos serveurs et de nos traitements de donn√©es.

## 4. üèóÔ∏è Architecture du Projet <a name="architecture-du-projet"></a>
Le projet est divis√© en plusieurs modules interconnect√©s, chacun jouant un r√¥le cl√© dans l'ensemble du syst√®me.

- **üõ†Ô∏è Module Collecte et Stockage des Donn√©es**
- **üõ†Ô∏è Module Traitement, Stockage et Visualisation**
- **üõ†Ô∏è Module Entra√Ænement et Suivi des Mod√®les**
- **üõ†Ô∏è Module D√©ploiement et Feedback**
- **üõ†Ô∏è Module d'Orchestration et Conteneurisation**
- **üõ†Ô∏è Module Int√©gration Continue (CI) et Tests Unitaires**

![Workflow_g√©neral](images/Workflow.png)

## 5. ‚öôÔ∏è Int√©gration Continue (CI) et Tests Unitaires <a name="int√©gration-continue-ci-et-tests-unitaires"></a>
Nous avons mis en place une int√©gration continue (CI) via **GitHub Actions**, qui ex√©cute des tests unitaires et des analyses statiques √† chaque commit sur les diff√©rents sous-projets.

### Outils utilis√©s pour la CI :
- **üß™ Pytest** pour l'ex√©cution des tests unitaires.
- **üîç Pylint, Black, Mypy** pour l'analyse statique du code et le respect des conventions de style. Nous avons obtenu un score de **10/10 sur Pylint**, garantissant un code de haute qualit√©.
- **üìä Coverage** pour mesurer la couverture des tests, avec un rapport g√©n√©r√© apr√®s chaque ex√©cution de CI afin d'assurer que l'ensemble du code est bien couvert par les tests.

Le pipeline de CI, configur√© dans le r√©pertoire `.github/workflows`, est accessible via [ce lien](https://github.com/keagnon/DetectionAnomalie/actions/runs/10837858597/job/30074776315).

En outre, chaque module du projet est containeris√© avec **Docker** pour assurer la portabilit√© et la coh√©rence des environnements. Les fichiers `.env` permettent une configuration flexible des variables d'environnement.

## 6. Calcul de l'Empreinte Carbone du Projet <a name="co2"></a>

Dans notre projet, nous avons int√©gr√© le calcul de l'empreinte carbone √† chaque sous-projet n√©cessitant beaucoup de calculs (comme l'entra√Ænement des mod√®les et les pipelines ETL ) afin d'√©valuer l'impact environnemental de chaque composant. √Ä travers l'utilisation d'outils tels que **CodeCarbon**, nous avons mesur√© les √©missions g√©n√©r√©es par les diff√©rentes √©tapes, allant du traitement des donn√©es √† l'entra√Ænement des mod√®les de machine learning, ainsi que l'ex√©cution des pipelines. Chaque sous-projet a donc √©t√© con√ßu pour suivre l'empreinte carbone associ√©e, permettant de comprendre o√π se concentrent les √©missions les plus importantes et de proposer des solutions d'optimisation.

En mesurant l'empreinte carbone g√©n√©r√©e par l'infrastructure du projet (serveurs, pipelines, ressources cloud) et les traitements des donn√©es (pr√©visions m√©t√©orologiques, mouvements sociaux), nous avons pu :
- Quantifier l'impact environnemental de chaque t√¢che et ajuster les ressources en cons√©quence.
- Explorer des moyens de r√©duction, comme l'utilisation de sources d'√©nergie renouvelable, l'optimisation des algorithmes pour r√©duire leur consommation √©nerg√©tique, ou encore le passage √† des infrastructures plus √©conomes en √©nergie.
- Fournir aux entreprises une estimation de leur propre impact carbone, en leur permettant de prendre des d√©cisions √©clair√©es pour minimiser cet impact √† chaque √©tape du processus.

Cette approche `"green AI"` nous a permis de concilier performance algorithmique et responsabilit√© √©cologique dans l'ensemble du projet.

## 7. üìÇ Structure du Projet <a name="structure-du-projet"></a>
(Ins√©rer la structure d√©taill√©e du projet ici)

Nous utilisons un **üõ†Ô∏è Makefile** pour automatiser les processus de build, de tests et faciliter la gestion de la CI en local. De plus, nos variables suivent le style `snake_case` et nous avons ajout√© des `docstrings` dans toutes les parties du projet.

## 8. üîÑ Pipelines de Collecte de Donn√©es avec Kedro <a name="pipelines-de-collecte-de-donn√©es-avec-kedro"></a>
Cette partie est un sous projet d√©velopper pour la partie ingestion des donn√©es et est inclus dans notre projet de d√©tection d'anomalie .
Deux pipelines Kedro ont √©t√© mis en place :
1. **Pipeline ETL** : Ce pipeline collecte, transforme et stocke les donn√©es dans MongoDB.
2. **Pipeline data fusion** : Ce pipeline charge les donn√©es, les fusionne et les stocke dans Elasticsearch.

Pour acc√©der √† ce sous projet et √†voir plus de d√©tails, consultez le [Acc√©der au sous projet data-collection-kedro](https://github.com/keagnon/DetectionAnomalie/blob/main/data-collection-kedro/README.md).


## 9. üíª Traitement des Donn√©es et Utilisation de Google Colab <a name="traitement-des-donn√©es-et-utilisation-de-google-colab"></a>
Certaines donn√©es volumineuses ont √©t√© trait√©es avec **Google Colab**, notamment pour les membres de l'√©quipe ayant des limitations mat√©rielles. Voici une capture d'√©cran de nos notebooks sur Google Colab ainsi que notre bucket GCP pour le stockage des donn√©es et artefacts.

![Capture du Bucket GCP](images/bucket.png)
![Capture google colab GCP](images/google_colab.png)

## 10. ü§ñ Mod√®les de Machine Learning <a name="mod√®les-de-machine-learning"></a>
Gr√¢ce √†nos pipelines de collecte, stockage et fusion des donn√©es, les donn√©es ont √©t√© divis√©es en deux groupes :
1. **Consommation journali√®re par r√©gion avec donn√©es m√©t√©orologiques**.
2. **Consommation journali√®re et mouvements sociaux** (avec une colonne "mouvement social" indiquant les jours avec des √©v√©nements).

Ces deux groupes de donn√©es ont conduit √† deux sous-projets distincts :
- [Acc√©der au sous-projet sur la consommation r√©gionale et les donn√©es m√©t√©o](lien_readme_conso_meteo).
- [Acc√©der au sous-projet sur la consommation et les mouvements sociaux](https://github.com/keagnon/DetectionAnomalie/blob/main/ml_models/mouvements_consommation/Readme.md).

Ces sous-projets, ainsi que notre interface Streamlit, utilisent **MLflow** pour le suivi et la mise en production des mod√®les. Un serveur **MLFlow** a √©t√© d√©ploy√© sur une VM GCP pour permettre √† l'√©quipe de suivre les performances des mod√®les.

## 11. üñ•Ô∏è Interface Utilisateur <a name="interface-utilisateur-avec-streamlit"></a>
L'interface utilisateur finale a √©t√© d√©velopp√©e avec **Streamlit**. Elle permet :
- Le t√©l√©chargement de datasets.
- La visualisation des r√©sultats des mod√®les de machine learning.
- La collecte de feedbacks utilisateurs.

![First_page_dashboard_ui](images/dashboard/interface_utilisateur.png)

Cette interface est un sous projet de notre projet de d√©tection d'anomalie. Elle est d√©ploy√©e localement et sur **Streamlit Community**. Pour acc√©der √† ce sous projet et avoir plus de d√©tails,cliquer sur [Sous projet Dashboard Streamlit](https://github.com/keagnon/DetectionAnomalie/blob/main/dashboard_ui/Readme.md).

## 12. üìä Documentation<a name="documentation"></a>
Nous avons document√© plusieurs √©tapes critiques du projet :
1. **Mise en place d‚Äôun serveur MLFlow sur GCP** : [documentation_mlflow](https://github.com/keagnon/DetectionAnomalie/blob/main/documentation/etapes_mise_en_place.pdf)
2. **Mise en place d‚Äôun serveur Airflow en local** : [documentation_airflow](https://github.com/keagnon/DetectionAnomalie/blob/main/documentation/etapes_installation_airflow.txt)
3. **Ordonnancement des Donn√©es** : [documentation_ordonnoncement](https://github.com/keagnon/DetectionAnomalie/blob/main/documentation/Ordonnoncements_donn%C3%A9es.pdf)
4. **Documentation amazone** : [documentation_amazone](https://github.com/keagnon/DetectionAnomalie/blob/main/documentation/Documentation_amazone%20S3.odt)
4. **Mise en place elastic search** : [documentation_elastic](https://github.com/keagnon/DetectionAnomalie/blob/main/documentation/Documentation%20mise%20en%20place%20elastic.pdf)
4. **Installation et configuration streamlit** : [documentation_elastic](https://github.com/keagnon/DetectionAnomalie/blob/main/documentation/Documentation%20mise%20en%20place%20elastic.pdf)

**Airflow** est utilis√© pour orchestrer les pipelines de collecte de donn√©es via des DAGs. Un exemple de DAG est utilis√© pour enrichir nos datasets avec des donn√©es d'API. Ce script Airflow s'ex√©cute toute les 30 minutes. Voici des images de notre DAG et de notre interface Airflow :

![Capture dag airflow](images/airflow/im1.png)
![Capture dag airflow](images/airflow/im2.png)
![Capture dag airflow](images/airflow/im3.png)


## 13. üìú Conclusion <a name="conclusion"></a>
Le projet de d√©tection d'anomalies dans la consommation d'√©nergie a permis de mettre en place une solution compl√®te, modulaire et scalable. Gr√¢ce √† l'int√©gration de diverses technologies, nous avons r√©ussi √† d√©velopper un syst√®me robuste capable d'identifier des anomalies dans les donn√©es de consommation √©nerg√©tique. En combinant des donn√©es m√©t√©orologiques, sociales et de consommation, nous avons pu g√©n√©rer des insights pr√©cieux qui aident les entreprises √† optimiser leur utilisation d'√©nergie.

## 14. ‚ö†Ô∏è Difficult√©s Rencontr√©es <a name="difficult√©s_rencontr√©es"></a>
Malgr√© les succ√®s obtenus, plusieurs d√©fis ont √©t√© rencontr√©s au cours du projet :

- **Gestion des Donn√©es Massives** : Le traitement de grands volumes de donn√©es, en particulier les pr√©visions m√©t√©orologiques et les mouvements sociaux, a pos√© des probl√®mes de performance, notamment sur les machines locales. Pour contourner ces limites, nous avons utilis√© Google Colab et Google Cloud Platform (GCP). Lors de la collecte des donn√©es avec Kedro, nous avons d√ª les traiter en lots (batch processing), et m√™me apr√®s la fusion des donn√©es, l'insertion dans Elasticsearch s'est faite en petits morceaux (chunks) pour √©viter des surcharges.

- **Int√©gration de Technologies Multiples** : L'int√©gration de divers outils et frameworks (Kedro, MLflow, Docker, Elasticsearch) a √©t√© un d√©fi, car certaines incompatibilit√©s et la gestion des d√©pendances ont ralenti le d√©veloppement. La configuration du serveur MLflow a √©galement n√©cessit√© des ajustements techniques complexes.

- **Disponibilit√© et Qualit√© des Donn√©es** : La collecte de donn√©es provenant de sources vari√©es (PDF, captures d'√©cran, fichiers XML) a cr√©√© des difficult√©s, notamment lors de la fusion des ensembles de donn√©es. Certaines p√©riodes manquaient de donn√©es, et certaines dates ne correspondaient pas, compliquant la cr√©ation d'un dataset coh√©rent.

- **Contraintes Budg√©taires** : Le manque de cr√©dits sur GCP a limit√© nos exp√©rimentations, obligeant certaines parties du projet √† √™tre d√©ploy√©es sur des infrastructures locales ("on-premise"), ce qui a restreint les capacit√©s et l'√©chelle des tests.

- **Donn√©es sur l‚ÄôEmpreinte Carbone** : Nous avons envisag√© d'incorporer des donn√©es sur l'empreinte carbone par r√©gion pour ajouter une dimension "green AI" au projet, o√π l‚Äôoptimisation de la consommation √©nerg√©tique des algorithmes serait un objectif. Cependant, ces donn√©es se sont av√©r√©es difficiles √† trouver. Chaque r√©gion ou secteur pourrait avoir un facteur d'√©mission diff√©rent, selon la source d‚Äô√©nergie utilis√©e. Cela aurait permis de pr√©dire la demande √©nerg√©tique tout en tenant compte des mouvements sociaux et de fournir des recommandations pour minimiser l‚Äôimpact carbone en ajustant les sources d‚Äô√©nergie (comme passer du charbon aux √©nergies renouvelables). Malheureusement, ces donn√©es √©taient insuffisantes pour mener √† bien cette analyse.


## 15. üöÄ Prochaines √âtapes : Phase 2 - Forecasting <a name="prochaine_etapes"></a>
La prochaine √©tape du projet est de passer √† la **Phase 2 : Forecasting**. Nous avons pour objectif d'√©tendre le syst√®me actuel pour inclure des mod√®les de pr√©vision bas√©s sur des s√©ries temporelles, afin d'anticiper les incidents futurs en se basant sur des donn√©es historiques et actuelles.

### Objectifs de la Phase 2 :
- **Pr√©diction des Risques d'Incidents** : Pr√©dire les risques d'incidents sur une p√©riode de 2 √† 3 mois.
- **Anticipation des Impacts** : Anticiper les impacts des conditions m√©t√©orologiques et des √©v√©nements sociaux sur la consommation √©nerg√©tique.
- **Optimisation de la Planification** : Aider les entreprises √† planifier et √† ajuster leurs strat√©gies en fonction des pr√©visions.

### D√©tails :
Nous avons d√©j√† r√©alis√© un Proof of Concept (PoC), et l'objectif sera de rendre le syst√®me capable d'effectuer des pr√©visions pr√©cises et pertinentes. En combinant les donn√©es de s√©ries temporelles avec les informations sur la consommation et les √©v√©nements ext√©rieurs, nous pourrons proposer des pr√©visions plus pr√©cises aux entreprises pour les aider √† optimiser leurs ressources et √©viter les incidents √©nerg√©tiques.

Le syst√®me actuel est con√ßu de mani√®re modulaire, ce qui permettra une transition fluide vers cette phase de forecasting et facilitera l'adaptation continue aux besoins changeants des entreprises et du march√©.
