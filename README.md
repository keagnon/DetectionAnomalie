# ğŸš€ DÃ©tection d'Anomalies dans la Consommation d'Ã‰nergie

### Langage

![Python Badge](https://img.shields.io/badge/python-3.11.5-blue)

### Frameworks et Outils de DÃ©veloppement

![Streamlit Badge](https://img.shields.io/badge/Streamlit-1.38.0-orange)
![MLFlow Badge](https://img.shields.io/badge/MLFlow-2.16.0-orange)
![Flask Badge](https://img.shields.io/badge/Flask-3.0.3-black)
![Docker Badge](https://img.shields.io/badge/Docker-Enabled-blue)
![Kedro Badge](https://img.shields.io/badge/Kedro-0.19.8-brightgreen)
![Pre-commit Badge](https://img.shields.io/badge/Pre--Commit--Hooks-4.6.0-blue)
![GitPython Badge](https://img.shields.io/badge/GitPython-3.1.43-orange)

### Empreinte Carbone

![CodeCarbon](https://img.shields.io/badge/CODECARBON-v1.2.0-brightgreen)

### Machine Learning & Data Science

![MLFlow Badge](https://img.shields.io/badge/MLFlow-2.16.0-orange)
![Pandas Badge](https://img.shields.io/badge/Pandas-2.2.2-brightgreen)
![Scikit-Learn Badge](https://img.shields.io/badge/Scikit--learn-1.5.1-orange)
![Matplotlib Badge](https://img.shields.io/badge/Matplotlib-3.9.2-blue)
![Plotly Badge](https://img.shields.io/badge/Plotly-5.24.0-blue)
![KMeans Badge](https://img.shields.io/badge/KMeans-Clustering-yellow)
![DBSCAN Badge](https://img.shields.io/badge/DBSCAN-Clustering-brightgreen)
![Isolation Forest Badge](https://img.shields.io/badge/Isolation--Forest-Anomaly%20Detection-blue)
![Ridge Regression Badge](https://img.shields.io/badge/Ridge--Regression-Prediction-lightblue)
![Random Forest Badge](https://img.shields.io/badge/Random--Forest-Prediction-brightgreen)
![CatBoost Badge](https://img.shields.io/badge/CatBoost-Prediction-orange)


### Cloud & Stockage

![Google Cloud Storage Badge](https://img.shields.io/badge/Google%20Cloud%20Storage-2.18.2-orange)
![Elasticsearch Badge](https://img.shields.io/badge/Elasticsearch-8.15.0-grey)
![PyMongo Badge](https://img.shields.io/badge/PyMongo-4.8.0-green)
![Boto3 Badge](https://img.shields.io/badge/Boto3-1.35.14-green)

### CI/CD et Outils de DÃ©bogage

![Pre-Commit Badge](https://img.shields.io/badge/Pre--Commit--Hooks-4.6.0-blue)
![Pytest](https://img.shields.io/badge/Pytest-8.3.2-blue)
![Mypy](https://img.shields.io/badge/Mypy-1.11.2-blue)
![Black](https://img.shields.io/badge/Black-23.11.0-black)
![Python](https://img.shields.io/badge/Python-3.11.5-blue)
![GitHub Actions Badge](https://img.shields.io/badge/GitHub--Actions-CI%2FCD-brightgreen)

### Librairies pour les Logs

![Elasticsearch](https://img.shields.io/badge/Elasticsearch-8.10.0-005571?style=for-the-badge&logo=elasticsearch)
![psutil](https://img.shields.io/badge/psutil-5.9.7-blue?style=for-the-badge)
![Loguru](https://img.shields.io/badge/Loguru-0.6.0-purple?style=for-the-badge&logo=logstash)

## ğŸ“‘ Sommaire
1. [ğŸ” Contexte du Projet](#contexte-du-projet)
2. [ğŸ’¡ Pourquoi ce projet ?](#pourquoi-ce-projet)
3. [ğŸ¯ Objectifs du Projet](#objectifs-du-projet)
4. [ğŸ¹ Nos cibles](#cibles)
5. [ğŸ—ï¸ Architecture du Projet](#architecture-du-projet)
6. [âš™ï¸ IntÃ©gration Continue (CI) et Tests Unitaires](#intÃ©gration-continue-ci-et-tests-unitaires)
7. [ğŸŒ Calcul de l'Empreinte Carbone du Projet](#co2)
8. [ğŸ“‚ Structure du Projet](#structure-du-projet)
9. [ğŸ”„ Pipelines de Collecte de DonnÃ©es avec Kedro](#pipelines-de-collecte-de-donnÃ©es-avec-kedro)
10. [ğŸ’» Traitement des DonnÃ©es et Utilisation de Google Colab](#traitement-des-donnÃ©es-et-utilisation-de-google-colab)
11. [ğŸ¤– ModÃ¨les de Machine Learning](#modÃ¨les-de-machine-learning)
12. [ğŸ–¥ï¸ Interface Utilisateur](#interface-utilisateur-avec-streamlit)
13. [ğŸ“ˆ Monitoring des Logs et Performance](#monitoring-des-logs)
14. [ğŸ“Š Documentation](#documentation)
15. [ğŸ“œ Conclusion](#conclusion)
16. [âš ï¸ DifficultÃ©s RencontrÃ©es](#difficultÃ©s_rencontrÃ©es)
17. [ğŸš€ Prochaines Ã‰tapes : Phase 2 - Forecasting ](#prochaine_etapes)
17. [ğŸ¤ Notre Ã‰quipe](#equipe)

## 1. ğŸ” Contexte du Projet<a name="contexte-du-projet"></a>
La dÃ©tection prÃ©coce des anomalies Ã©nergÃ©tiques est essentielle pour la gestion proactive de l'Ã©nergie, en particulier pendant les pÃ©riodes de forte demande (hiver, Ã©tÃ©) ou durant des Ã©vÃ©nements comme les mouvements sociaux. Ce projet vise Ã  identifier ces anomalies en se basant sur des donnÃ©es variÃ©es (mÃ©tÃ©orologiques, sociales, etc.) et Ã  fournir une interface utilisateur permettant la visualisation et l'analyse des rÃ©sultats. La solution est structurÃ©e en quatre sous-projets interconnectÃ©s, chacun ayant des objectifs spÃ©cifiques et incluant un ou plusieurs modules.


## 2. ğŸ’¡ Pourquoi ce projet ? <a name="pourquoi-ce-projet"></a>
Nous avons identifiÃ© plusieurs dÃ©fis majeurs dans la gestion Ã©nergÃ©tique :
- **Surconsommation en Hiver et en Ã‰tÃ©** : Augmentation significative de la demande en Ã©lectricitÃ© pendant les pÃ©riodes de froid ou de chaleur extrÃªme.
- **Jours FÃ©riÃ©s et Mouvements Sociaux** : Les variations imprÃ©vues dans la consommation peuvent dÃ©sÃ©quilibrer l'offre et la demande.

## 3. ğŸ¹ Nos cibles<a name="cibles"></a>
Nos cibles principales incluent :
- **Entreprises d'Ã‰lectricitÃ©** (comme Engie et EDF) qui doivent surveiller la consommation en temps rÃ©el et ajuster leur production.
- **Industries Ã  Forte Consommation** qui nÃ©cessitent une gestion optimale de leur Ã©nergie pour Ã©viter des interruptions.

## 4. ğŸ¯ Objectifs du Projet <a name="objectifs-du-projet"></a>
Notre projet se concentre sur six grands objectifs :
1. **ğŸ” DÃ©tection des Anomalies** : Identifier en temps rÃ©el les anomalies de consommation.
2. **ğŸ“ˆ PrÃ©diction de la consommation** : Utiliser des modÃ¨les prÃ©dictifs pour prÃ©dire la consommation.
3. **âš¡ Optimisation des Ressources** : Aider les entreprises Ã  optimiser leur consommation Ã©nergÃ©tique.
4. **ğŸ”„ AmÃ©lioration Continue** : IntÃ©grer les retours des utilisateurs pour perfectionner notre systÃ¨me.
5. **ğŸŒ RÃ©duction de l'Empreinte Carbone** : Calculer l'impact carbone de nos serveurs et de nos traitements de donnÃ©es.

## 5. ğŸ—ï¸ Architecture du Projet <a name="architecture-du-projet"></a>
Le projet est divisÃ© en plusieurs modules interconnectÃ©s, chacun jouant un rÃ´le clÃ© dans l'ensemble du systÃ¨me.

- **ğŸ› ï¸ Module Collecte et Stockage des DonnÃ©es**
- **ğŸ› ï¸ Module Traitement, Stockage et Visualisation**
- **ğŸ› ï¸ Module EntraÃ®nement et Suivi des ModÃ¨les**
- **ğŸ› ï¸ Module DÃ©ploiement et Feedback**
- **ğŸ› ï¸ Module d'Orchestration et Conteneurisation**
- **ğŸ› ï¸ Module IntÃ©gration Continue (CI) et Tests Unitaires**
- **ğŸ› ï¸ Module Surveillance des logs**

![Workflow_gÃ©neral](images/Workflow.png)

## 6. âš™ï¸ IntÃ©gration Continue (CI) et Tests Unitaires <a name="intÃ©gration-continue-ci-et-tests-unitaires"></a>
Nous avons mis en place une intÃ©gration continue (CI) via **GitHub Actions**, qui exÃ©cute des tests unitaires et des analyses statiques Ã  chaque commit sur les diffÃ©rents sous-projets.

### Outils utilisÃ©s pour la CI :
- **ğŸ§ª Pytest** pour l'exÃ©cution des tests unitaires.
- **ğŸ” Pylint, Black, Mypy** pour l'analyse statique du code et le respect des conventions de style. Nous avons obtenu un score de **10/10 sur Pylint**, garantissant un code de haute qualitÃ©.
- **ğŸ“Š Coverage** pour mesurer la couverture des tests, avec un rapport gÃ©nÃ©rÃ© aprÃ¨s chaque exÃ©cution de CI afin d'assurer que l'ensemble du code est bien couvert par les tests.

Le pipeline de CI, configurÃ© dans le rÃ©pertoire `.github/workflows`, est accessible via [ce lien](https://github.com/keagnon/DetectionAnomalie/actions/runs/10871125104/job/30164567486).

Nous utilisons un **ğŸ› ï¸ Makefile** pour automatiser les processus de build, de tests et faciliter la gestion de la CI en local. Voici un aperÃ§u de notre fichier `Makefile` :
![CI local](images/Makefile.png)

En outre, chaque module du projet est containerisÃ© avec **Docker** pour assurer la portabilitÃ© et la cohÃ©rence des environnements. Les fichiers `.env` permettent une configuration flexible des variables d'environnement.

## 7. Calcul de l'Empreinte Carbone du Projet <a name="co2"></a>

Dans le cadre de notre projet, nous avons intÃ©grÃ© le calcul de l'empreinte carbone pour chaque composant nÃ©cessitant des ressources de calcul intensives (modÃ¨les, pipelines ETL, etc.). GrÃ¢ce Ã  CodeCarbon, nous avons mesurÃ© les Ã©missions en CO2eq gÃ©nÃ©rÃ©es par chaque tÃ¢che, de la prÃ©paration des donnÃ©es Ã  l'entraÃ®nement des modÃ¨les.

RÃ©sultats :
- **Empreinte carbone trÃ¨s faible**: Les processus les plus gourmands, comme l'entraÃ®nement du modÃ¨le CatBoost, restent en dessous de 0.00043 kgCO2eq, tandis que les autres modÃ¨les et pipelines ont un impact nÃ©gligeable.
- **Optimisation Ã©nergÃ©tique**: Ces rÃ©sultats montrent que le projet est optimisÃ© pour allier efficacitÃ© Ã©nergÃ©tique et performances Ã©levÃ©es, garantissant une faible empreinte environnementale tout en rÃ©pondant aux exigences de traitement de donnÃ©es.

**Empreinte carbone totale**:
Voici un aperÃ§u des Ã©missions en CO2eq gÃ©nÃ©rÃ©es par les diffÃ©rentes parties du projet :

![empreinte_carbone_totale](images/logs_empreinte_carbone/total_empreinte_carbone.png)

Cette approche `"green AI"` nous a permis de concilier performance algorithmique et responsabilitÃ© Ã©cologique dans l'ensemble du projet.

## 8. ğŸ“‚ Structure du Projet <a name="structure-du-projet"></a>
```
ğŸ“‚ DETECTIONANOMALIE
â”œâ”€â”€ .github/                  # Configuration GitHub (actions, workflows, etc.)
â”œâ”€â”€ .mypy_cache/              # Cache pour l'analyse statique mypy
â”œâ”€â”€ dashboard_ui/             # Interface utilisateur avec Streamlit
â”‚   â”œâ”€â”€ app.py                # Point d'entrÃ©e principal pour l'application Streamlit
â”‚   â”œâ”€â”€ Dockerfile            # Fichier de configuration pour le dÃ©ploiement Docker
â”‚   â”œâ”€â”€ requirements.txt      # Liste des dÃ©pendances Python
â”‚   â”œâ”€â”€ .env                  # Fichier des variables d'environnement (non suivi par Git)
â”‚   â”œâ”€â”€ styles.css            # Fichier pour les styles CSS
â”‚   â”œâ”€â”€ page_anomalie_detection.py  # Page de dÃ©tection d'anomalies
â”‚   â”œâ”€â”€ page_clustering.py         # Page pour les clusters des rÃ©gions de consommation
â”‚   â”œâ”€â”€ page_feedback.py           # Page pour recueillir les retours utilisateurs
â”‚   â”œâ”€â”€ page_prediction_conso.py   # Page pour la prÃ©diction de consommation Ã©nergÃ©tique
â”‚   â”œâ”€â”€ page_prediction_meteo.py   # Page pour les prÃ©dictions basÃ©es sur les donnÃ©es mÃ©tÃ©o
â”‚   â”œâ”€â”€ page_tracking.py           # Page de suivi avec MLflow
â”‚   â””â”€â”€ utils.py                   # Fichier contenant des fonctions utilitaires pour l'application
â”‚
â”œâ”€â”€ data-collection-kedro/    # Pipelines pour la collecte de donnÃ©es (via Kedro)
â”‚   â””â”€â”€ ...                   # Contient les pipelines et scripts de collecte
â”‚
â”œâ”€â”€ documentation/            # Documentation pour le projet
â”‚   â””â”€â”€ ...                   # Manuels, guides, et fichiers explicatifs
â”‚
â”œâ”€â”€ images/                   # Images utilisÃ©es dans la documentation ou l'application
â”‚   â””â”€â”€ ...                   # Fichiers d'images
â”‚
â”œâ”€â”€ ml_models/                # ModÃ¨les de Machine Learning utilisÃ©s
â”‚   â”œâ”€â”€ meteo_consommation/   # ModÃ¨les liÃ©s Ã  la mÃ©tÃ©o
â”‚   â””â”€â”€ mouvements_consommation/ # ModÃ¨les liÃ©s aux mouvements sociaux
â”‚
â”œâ”€â”€ notebooks/                # Notebooks Jupyter pour l'exploration des donnÃ©es
â”‚   â””â”€â”€ ...                   # Fichiers .ipynb pour les tests et expÃ©rimentations
â”‚
â”œâ”€â”€ scripts/                  # Scripts divers pour le projet
â”‚   â”œâ”€â”€ airflow/              # Configuration et scripts pour Airflow
â”‚   â”œâ”€â”€ empreinte_carbone_projet/ # Scripts pour calculer l'empreinte carbone
â”‚   â”œâ”€â”€ feedback/             # Scripts pour gÃ©rer les retours utilisateurs
â”‚   â””â”€â”€ template_mlflow_team/ # Templates et configuration pour le suivi MLflow en Ã©quipe
â”‚
â”œâ”€â”€ .gitignore                # Fichier pour exclure certains fichiers du contrÃ´le Git
â”œâ”€â”€ Makefile                  # Automatisation de tÃ¢ches courantes (tests, dÃ©ploiement, etc.)
â”œâ”€â”€ README.md                 # Documentation principale du projet
â”œâ”€â”€ requirements_test.txt     # Liste des dÃ©pendances pour les tests
â””â”€â”€ requirements.txt          # Liste des dÃ©pendances gÃ©nÃ©rales du projet
```

<br>

**N.B** : Nos variables suivent le style `snake_case` et nous avons ajoutÃ© des `docstrings` dans toutes les parties du projet.

## 9. ğŸ”„ Pipelines de Collecte de DonnÃ©es avec Kedro <a name="pipelines-de-collecte-de-donnÃ©es-avec-kedro"></a>
Cette partie du projet est un sous-projet dÃ©diÃ© Ã  l'ingestion et Ã  la prÃ©paration des donnÃ©es, inclus dans notre projet global de dÃ©tection d'anomalies. Deux pipelines Kedro ont Ã©tÃ© mis en place pour gÃ©rer ces donnÃ©es et les rendre disponibles pour l'analyse et la visualisation :

1. **Pipeline ETL** : Ce pipeline collecte les donnÃ©es brutes Ã  partir de diffÃ©rentes sources, les transforme (nettoyage, enrichissement, etc.) et les stocke ensuite dans une base de donnÃ©es MongoDB. Le stockage dans MongoDB centralise les donnÃ©es transformÃ©es pour une utilisation ultÃ©rieure.

2. **Pipeline de Fusion des DonnÃ©es (data fusion)** : Ce pipeline charge les donnÃ©es depuis MongoDB, les fusionne pour crÃ©er un ensemble de donnÃ©es cohÃ©rent, puis les stocke dans Elasticsearch. Le stockage dans Elasticsearch facilite l'indexation et la visualisation des donnÃ©es.

Pour accÃ©der Ã  ce sous projet et avoir plus de dÃ©tails, consultez le [AccÃ©der au sous projet data-collection-kedro](https://github.com/keagnon/DetectionAnomalie/blob/main/data-collection-kedro/README.md).


![visualisation donnee brute](images/data_viz_kibana/dasboard_donnee_brute.png)

Câ€™est grÃ¢ce Ã  la visualisation des donnÃ©es brutes dans Kibana que nous avons pu extraire des indicateurs clÃ©s de performance (KPI). Cette Ã©tape de visualisation a Ã©tÃ© cruciale pour comprendre les tendances et les anomalies prÃ©sentes dans les donnÃ©es, et a ainsi permis de dÃ©finir et de suivre des KPI pertinents.
<br>
Pour plus de dÃ©tails, consultez l'[interprÃ©tation des donnÃ©es brutes collectÃ©es visualisÃ©es](https://github.com/keagnon/DetectionAnomalie/tree/main/data-collection-kedro#visualisation-des-donn%C3%A9es-brutes-collect%C3%A9es).


## 10. ğŸ’» Traitement des DonnÃ©es et Utilisation de Google Colab <a name="traitement-des-donnÃ©es-et-utilisation-de-google-colab"></a>
Certaines donnÃ©es volumineuses ont Ã©tÃ© traitÃ©es avec **Google Colab**, notamment pour les membres de l'Ã©quipe ayant des limitations matÃ©rielles. Voici une capture d'Ã©cran de nos notebooks sur Google Colab ainsi que notre bucket GCP pour le stockage des donnÃ©es et artefacts.

![Capture google colab GCP](images/google_colab.png)
![Capture du Bucket GCP](images/bucket.png)

## 11. ğŸ¤– ModÃ¨les de Machine Learning <a name="modÃ¨les-de-machine-learning"></a>
GrÃ¢ce Ã  nos pipelines de collecte, stockage et fusion des donnÃ©es, les donnÃ©es ont Ã©tÃ© divisÃ©es en deux groupes :
1. **Consommation journaliÃ¨re par rÃ©gion avec donnÃ©es mÃ©tÃ©orologiques**.
2. **Consommation journaliÃ¨re et mouvements sociaux** (avec une colonne "mouvement social" indiquant les jours avec des Ã©vÃ©nements).

Ces deux groupes de donnÃ©es ont conduit Ã  deux sous-projets distincts :
- [AccÃ©der au sous-projet dÃ©veloppement modÃ¨les ML pour les donnÃ©es sur la consommation rÃ©gionale et les donnÃ©es mÃ©tÃ©o](https://github.com/keagnon/DetectionAnomalie/blob/main/ml_models/meteo_consommation/meteo/README.md).
- [AccÃ©der au sous-projet dÃ©veloppement modÃ¨les ML pour les donnÃ©es sur la consommation rÃ©gionale et les mouvements sociaux](https://github.com/keagnon/DetectionAnomalie/blob/main/ml_models/mouvements_consommation/Readme.md).

Ces sous-projets, ainsi que notre interface Streamlit, utilisent **MLflow** pour le suivi et la mise en production des modÃ¨les.

<br>

**N.B** : Un serveur **MLFlow** a Ã©tÃ© dÃ©ployÃ© sur une VM GCP pour permettre Ã  l'Ã©quipe de suivre les performances des modÃ¨les.

## 12. ğŸ–¥ï¸ Interface Utilisateur <a name="interface-utilisateur-avec-streamlit"></a>
L'interface utilisateur finale a Ã©tÃ© dÃ©veloppÃ©e avec **Streamlit** et du **CSS**. Elle permet :
- Le tÃ©lÃ©chargement de datasets ;
- L'interaction avec les modÃ¨les de machine learning dÃ©veloppÃ©s ;
- La collecte de feedbacks utilisateurs ;
- L'accÃ¨s Ã  notre serveur **Mlflow**.

![First_page_dashboard_ui](images/dashboard/interface_utilisateur.png)

Sur l'interface utilisateur que nous avons dÃ©veloppÃ©e, quatre onglets sont disponibles, chacun correspondant Ã  un modÃ¨le de machine learning diffÃ©rent. Ces modÃ¨les communiquent avec **MLflow** pour effectuer les prÃ©dictions en temps rÃ©el. Chaque onglet permet d'interagir avec un modÃ¨le spÃ©cifique, dont **IsolationForest** pour la dÃ©tection d'anomalies, **CatBoost**, **RandomForest**, et **DBSCAN**.

Cette interface est un sous projet de notre projet de dÃ©tection d'anomalie. Elle est dÃ©ployÃ©e localement. Pour accÃ©der Ã  ce sous projet et avoir plus de dÃ©tails, cliquez sur [Sous projet Dashboard Streamlit CSS](https://github.com/keagnon/DetectionAnomalie/blob/main/dashboard_ui/Readme.md).


## ğŸ“ˆ Monitoring des Logs et Performance <a name="monitoring-des-logs"></a>

Le **monitoring des logs** est essentiel pour suivre l'Ã©tat de l'application en temps rÃ©el et identifier rapidement des erreurs potentielles, des anomalies dans les prÃ©dictions ou des problÃ¨mes de performance. Pour cela, nous avons mis en place un systÃ¨me de journalisation unifiÃ© qui enregistre les Ã©vÃ©nements clÃ©s de l'application, notamment :

- **ExÃ©cution des modÃ¨les** : suivi des performances, de l'utilisation des ressources systÃ¨me (CPU, mÃ©moire), et des rÃ©sultats de chaque prÃ©diction.
- **PrÃ©dictions de consommation** et **dÃ©tection d'anomalies** : chaque prÃ©diction est loggÃ©e avec des dÃ©tails comme les entrÃ©es utilisateur et les rÃ©sultats, ainsi que les anomalies dÃ©tectÃ©es par les modÃ¨les.
- **Logs de performance** : utilisation de la bibliothÃ¨que `psutil` pour monitorer l'usage du CPU et de la mÃ©moire.

Ces logs sont ensuite envoyÃ©s Ã  **Elasticsearch** pour une analyse approfondie Ã  travers un tableau de bord **Kibana**, offrant une vue claire de l'Ã©tat de l'application et facilitant la prise de dÃ©cision.

Voici une capture d'Ã©cran de l'interface d'**Elasticsearch** montrant les logs unifiÃ©s et les diffÃ©rents Ã©vÃ©nements enregistrÃ©s dans l'application :
![Elasticsearch Logs](images/monitoring/im1.png)

Voici une capture d'Ã©cran du **tableau de bord Kibana** avec les diffÃ©rentes mÃ©triques suivies : <br>
![Kibana Dashboard](images/monitoring/dashboard_logs.png)

Le tableau de bord ci-dessus montre clairement que nous avons quatre modÃ¨les de machine learning : **IsolationForest** pour la dÃ©tection d'anomalies, **CatBoost**, **RandomForest**, et **DBSCAN**. Chacun de ces modÃ¨les est suivi en temps rÃ©el avec des indicateurs clÃ©s tels que le temps de rÃ©ponse, l'utilisation du CPU et de la mÃ©moire. Par exemple, **IsolationForest** est le plus utilisÃ© avec prÃ¨s de 44 % des exÃ©cutions, suivi par **CatBoost** (34,84 %), **RandomForest** (12,18 %) et **DBSCAN** (9,01 %).

Le graphique sur le nombre d'exÃ©cutions rÃ©ussies et Ã©chouÃ©es montre que **IsolationForest** est non seulement le plus utilisÃ©, mais aussi celui avec le plus d'exÃ©cutions complÃ¨tes, tandis que les autres modÃ¨les comme **DBSCAN** ont moins d'exÃ©cutions globales. Cela donne un aperÃ§u des performances de chaque modÃ¨le et permet de suivre la fiabilitÃ© des prÃ©dictions.

En complÃ©ment, l'historique des erreurs recense les problÃ¨mes rencontrÃ©s par les diffÃ©rents modÃ¨les. On peut y voir, par exemple, des erreurs `NameError` pour **IsolationForest** et **CatBoost**, facilitant ainsi l'identification des dysfonctionnements et leur rÃ©solution rapide pour amÃ©liorer les performances des modÃ¨les.

Ce tableau de bord centralise toutes les informations nÃ©cessaires pour surveiller les exÃ©cutions, identifier les erreurs et optimiser les ressources.

Pour plus de dÃ©tails, cliquez sur [Monitoring et logs unifiÃ©s](https://github.com/keagnon/DetectionAnomalie/tree/main/dashboard_ui#monitoring-et-logs-unifies)

## 14. ğŸ“Š Documentation <a name="documentation"></a>
Nous avons documentÃ© plusieurs Ã©tapes critiques du projet :
1. **Mise en place dâ€™un serveur MLFlow sur GCP** : [documentation_mlflow](https://github.com/keagnon/DetectionAnomalie/blob/main/documentation/etapes_mise_en_place.pdf)
2. **Mise en place dâ€™un serveur Airflow en local** : [documentation_airflow](https://github.com/keagnon/DetectionAnomalie/blob/main/documentation/etapes_installation_airflow.txt)
3. **Ordonnancement des DonnÃ©es** : [documentation_ordonnoncement](https://github.com/keagnon/DetectionAnomalie/blob/main/documentation/Ordonnoncements_donn%C3%A9es.pdf)
4. **Documentation amazone** : [documentation_amazone](https://github.com/keagnon/DetectionAnomalie/blob/main/documentation/Documentation_amazone%20S3.odt)
5. **Mise en place elastic search** : [documentation_elastic](https://github.com/keagnon/DetectionAnomalie/blob/main/documentation/Documentation%20mise%20en%20place%20elastic.pdf)
6. **Installation et configuration streamlit** : [documentation_elastic](https://github.com/keagnon/DetectionAnomalie/blob/main/documentation/Documentation%20mise%20en%20place%20elastic.pdf)
7. **Mise en Place des Logs et du Monitoring avec Elasticsearch et Kibana** : [documentation_monitoring_logs](https://github.com/keagnon/DetectionAnomalie/blob/main/documentation/Documentation%20de%20la%20Mise%20en%20Place%20des%20Logs%20et%20du%20Monitoring%20avec%20Elasticsearch%20et%20Kibana.pdf)


**Airflow** est utilisÃ© pour orchestrer les pipelines de collecte de donnÃ©es via des DAGs. Un exemple de DAG est utilisÃ© pour enrichir nos datasets avec des donnÃ©es d'API. Ce script Airflow s'exÃ©cute toute les 30 minutes. Voici des images de notre DAG et de notre interface Airflow :

![Capture dag airflow](images/airflow/im1.png)
![Capture dag airflow](images/airflow/im2.png)
![Capture dag airflow](images/airflow/im3.png)


## 15. ğŸ“œ Conclusion <a name="conclusion"></a>
Le projet de dÃ©tection d'anomalies dans la consommation d'Ã©nergie a permis de mettre en place une solution complÃ¨te, modulaire et scalable. GrÃ¢ce Ã  l'intÃ©gration de diverses technologies, nous avons rÃ©ussi Ã  dÃ©velopper un systÃ¨me robuste capable d'identifier des anomalies dans les donnÃ©es de consommation Ã©nergÃ©tique. En combinant des donnÃ©es mÃ©tÃ©orologiques, sociales et de consommation, nous avons pu gÃ©nÃ©rer des insights prÃ©cieux qui aident les entreprises Ã  optimiser leur utilisation d'Ã©nergie.

## 16. âš ï¸ DifficultÃ©s RencontrÃ©es <a name="difficultÃ©s_rencontrÃ©es"></a>
Bien que des succÃ¨s aient Ã©tÃ© obtenus, plusieurs dÃ©fis ont Ã©tÃ© rencontrÃ©s au cours du projet:

- **Gestion des DonnÃ©es Massives** : Le traitement de grands volumes de donnÃ©es, en particulier les prÃ©visions mÃ©tÃ©orologiques et les mouvements sociaux, a posÃ© des problÃ¨mes de performance, notamment sur les machines locales. Pour contourner ces limites, nous avons utilisÃ© Google Colab et Google Cloud Platform (GCP). Lors de la collecte des donnÃ©es avec Kedro, nous avons dÃ» les traiter en lots (batch processing), et mÃªme aprÃ¨s la fusion des donnÃ©es, l'insertion dans Elasticsearch s'est faite en petits morceaux (chunks) pour Ã©viter des surcharges.

- **IntÃ©gration de Technologies Multiples** : L'intÃ©gration de divers outils et frameworks (Kedro, MLflow, Docker, Elasticsearch) a Ã©tÃ© un dÃ©fi, car certaines incompatibilitÃ©s et la gestion des dÃ©pendances ont ralenti le dÃ©veloppement. La configuration du serveur MLflow a Ã©galement nÃ©cessitÃ© des ajustements techniques complexes.

- **DisponibilitÃ© et QualitÃ© des DonnÃ©es** : La collecte de donnÃ©es provenant de sources variÃ©es (PDF, captures d'Ã©cran, fichiers XML) a crÃ©Ã© des difficultÃ©s, notamment lors de la fusion des ensembles de donnÃ©es. Certaines pÃ©riodes manquaient de donnÃ©es, et certaines dates ne correspondaient pas, compliquant la crÃ©ation d'un dataset cohÃ©rent.

- **Contraintes BudgÃ©taires** : Le manque de crÃ©dits sur GCP a limitÃ© nos expÃ©rimentations, obligeant certaines parties du projet Ã  Ãªtre dÃ©ployÃ©es sur des infrastructures locales ("on-premise"), ce qui a restreint les capacitÃ©s et l'Ã©chelle des tests.


## 17. ğŸš€ Prochaines Ã‰tapes : Phase 2 - Forecasting <a name="prochaine_etapes"></a>
La prochaine Ã©tape du projet est de passer Ã  la **Phase 2 : Forecasting**. Nous avons pour objectif d'Ã©tendre le systÃ¨me actuel pour inclure des modÃ¨les de prÃ©vision basÃ©s sur des sÃ©ries temporelles, afin d'anticiper les incidents futurs en se basant sur des donnÃ©es historiques et actuelles.

### Objectifs de la Phase 2 :
- **PrÃ©diction des Risques d'Incidents** : PrÃ©dire les risques d'incidents sur une pÃ©riode de 2 Ã  3 mois.
- **Anticipation des Impacts** : Anticiper les impacts des conditions mÃ©tÃ©orologiques et des Ã©vÃ©nements sociaux sur la consommation Ã©nergÃ©tique.
- **Optimisation de la Planification** : Aider les entreprises Ã  planifier et Ã  ajuster leurs stratÃ©gies en fonction des prÃ©visions.

### DÃ©tails :
Nous avons dÃ©jÃ  rÃ©alisÃ© un Proof of Concept (PoC), et l'objectif sera de rendre le systÃ¨me capable d'effectuer des prÃ©visions prÃ©cises et pertinentes. En combinant les donnÃ©es de sÃ©ries temporelles avec les informations sur la consommation et les Ã©vÃ©nements extÃ©rieurs, nous pourrons proposer des prÃ©visions plus prÃ©cises aux entreprises pour les aider Ã  optimiser leurs ressources et Ã©viter les incidents Ã©nergÃ©tiques.

Le systÃ¨me actuel est conÃ§u de maniÃ¨re modulaire, ce qui permettra une transition fluide vers cette phase de forecasting et facilitera l'adaptation continue aux besoins changeants des entreprises et du marchÃ©.


## 18. ğŸ¤ Notre Ã‰quipe <a name="equipe"></a>
Parce que le succÃ¨s se construit ensemble, voici notre Ã©quipe prÃªte Ã  transformer des idÃ©es en rÃ©alitÃ© ğŸŒŸ.

![Image de l'Ã©quipe](images/team.jpg)